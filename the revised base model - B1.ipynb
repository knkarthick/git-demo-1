{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B1_Removed_Upsampling_Block,_brought_all_images_to_256_x_256.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb-q160odT3_"
      },
      "source": [
        "Development of B1: \"the revised base model\"\n",
        "\n",
        "in this notebook, all input images and corresponding ground truths are brought to the same size 256 x256. after doing this, Up-sampling block needed to restore the image to different input image sizes won't be required. \n",
        "Also, regions of non-interest are treated as below - \n",
        "1. Label between 0 to 0.19 is assigned ‘0’\n",
        "2. Label between 0.19 to 0.8 is assigned ‘-1’\n",
        "3. Label between 0.8 to 1 is assigned ‘1’ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z4_854loqmo",
        "outputId": "8d8d597a-2637-44e2-928f-7e86192d9630"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahgv8zxbpY33"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTEgHlHopFaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad7609b-b86e-44f1-bd87-75f160efcae6"
      },
      "source": [
        "pip install tensorflow==2.1.0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 28.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 71.6 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.13.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.42.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=0a1b326747d440c49e9d57d0541a9ae5fd81cbc243599474515c8c94cefd326e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKG9UgMhpVNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1605cfc6-42cf-4b02-eda7-861ce27dc732"
      },
      "source": [
        "pip install keras==2.3.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.3.0\n",
            "  Downloading Keras-2.3.0-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 377 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.0) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "Successfully installed keras-2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki-HoOtyiQUB",
        "outputId": "98a72de1-644e-4d62-89a1-6ae25d1e4398"
      },
      "source": [
        "!pip install -U scikit-learn==0.24"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.24\n",
            "  Downloading scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "Successfully installed scikit-learn-0.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNpLDohSqlCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f106d1-f64d-4b97-85fe-17306022cc02"
      },
      "source": [
        "# importing the required package\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "import os, sys\n",
        "import time\n",
        "from keras import backend as K\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import PIL.Image\n",
        "import keras, glob\n",
        "from keras.preprocessing import image as kImage\n",
        "from skimage.transform import pyramid_gaussian\n",
        "from sklearn.utils import compute_class_weight\n",
        "#from FgSegNet_M_S_module import FgSegNet_M_S_module # Prashanna has to check for this\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation, Input, Dropout, BatchNormalization, SpatialDropout2D\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D, Cropping2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras import regularizers\n",
        "from keras.engine.topology import Layer\n",
        "from keras.utils import conv_utils\n",
        "from keras.legacy import interfaces\n",
        "from keras.engine.base_layer import InputSpec\n",
        "\n",
        "#from my_upsampling_2d import MyUpSampling2D # Prashanna to check the need for this"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxbd3nPyeBx5"
      },
      "source": [
        "# print the entire array without truncation\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ulMo4_q7G2"
      },
      "source": [
        "# For reproducing the environment\n",
        "np.random.seed(42)\n",
        "rn.seed(12345)\n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gcDD3RUrzIt"
      },
      "source": [
        "# Define Data Generator (Inspired by FgSegNet)\n",
        "def generateData(train_dir, dataset_dir, scene, method_name):\n",
        "    void_label = -1. # defining label to be assigned to non-RoI\n",
        "    \n",
        "    # Given ground-truths, load training frames\n",
        "    # ground-truths end with '*.png'\n",
        "    # training frames end with '*.jpg'\n",
        "    \n",
        "    # given ground-truths, load inputs  \n",
        "    Y_list = glob.glob(os.path.join(train_dir, '*.png')) #stores the location of all the 50 files in ground truth.\n",
        "    X_list= glob.glob(os.path.join(dataset_dir, 'input','*.jpg')) #stores the location of all files in input directory\n",
        "\n",
        "    #for every file name in Ground Truth (Y) find the corresponding file in Input directory (X)\n",
        "    X_list_temp = []\n",
        "    for i in range(len(Y_list)):\n",
        "        Y_name = os.path.basename(Y_list[i]) \n",
        "        Y_name = Y_name.split('.')[0]\n",
        "        Y_name = Y_name.split('gt')[1]\n",
        "        for j in range(len(X_list)):\n",
        "            X_name = os.path.basename(X_list[j])\n",
        "            X_name = X_name.split('.')[0]\n",
        "            X_name = X_name.split('in')[1]\n",
        "            if (Y_name == X_name):\n",
        "                X_list_temp.append(X_list[j])\n",
        "                break\n",
        "            \n",
        "    X_list = X_list_temp # X corresponding to Ground Truth created\n",
        "    \n",
        "    # X must be corresponded to Y\n",
        "    X_list = sorted(X_list)\n",
        "    Y_list = sorted(Y_list)\n",
        "\n",
        "    # load training data\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in range(len(X_list)):\n",
        "        x = kImage.load_img(X_list[i]) # load image\n",
        "        x = x.resize((256, 256))\n",
        "        x = kImage.img_to_array(x) # convert the loaded image to array\n",
        "        X.append(x) # create X\n",
        "        \n",
        "        x = kImage.load_img(Y_list[i], grayscale = True) # load Y image\n",
        "        x = x.resize((256, 256))\n",
        "        x = kImage.img_to_array(x) # convert to array\n",
        "        shape = x.shape # shape of Y (height x width x 1)\n",
        "        x /= 255.0 # normalize to fit the range 0 to 1\n",
        "        x = x.reshape(-1) # flatten to find out pixels corresponding to non-ROI\n",
        "        idx = np.where(np.logical_and(x>0.19, x<0.8))[0] # find non-ROI\n",
        "        if (len(idx)>0):\n",
        "            x[idx] = void_label # assigning -1 to the non-ROI region of image\n",
        "        x = x.reshape(shape) # reshape the image back to original size\n",
        "        x = np.floor(x) #floor to the nearest integer. so now we have only 3 values: -1, 0, 1\n",
        "        Y.append(x) #create list of Y\n",
        "   \n",
        "   # Convert X and Y to array     \n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "        \n",
        "    # We do not consider temporal data. soo shuffle 0 to 49 and then apply the shuffled list to X and Y\n",
        "    idx = list(range(X.shape[0])) \n",
        "    np.random.shuffle(idx)\n",
        "    np.random.shuffle(idx)\n",
        "    X = X[idx]\n",
        "    Y = Y[idx]\n",
        "    \n",
        "    # compute class weights\n",
        "    cls_weight_list = [] # initialize the list\n",
        "    for i in range(Y.shape[0]): # for in in range 50\n",
        "        y = Y[i].reshape(-1) # flatten Y\n",
        "        idx = np.where(y!=void_label)[0] # find out the pixels that are marked as -1 (non ROI)\n",
        "        if(len(idx)>0):\n",
        "            y = y[idx] #find out all the non -1 entries in Y\n",
        "        lb = np.unique(y) #  0., 1\n",
        "        cls_weight = compute_class_weight('balanced', lb , y)\n",
        "        class_0 = cls_weight[0]\n",
        "        class_1 = cls_weight[1] if len(lb)>1 else 1.0\n",
        "        \n",
        "        cls_weight_dict = {0:class_0, 1: class_1}\n",
        "        cls_weight_list.append(cls_weight_dict)\n",
        "\n",
        "    cls_weight_list = np.asarray(cls_weight_list)\n",
        "    \n",
        "    return [X,Y,cls_weight_list]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qx-44IksIMd"
      },
      "source": [
        "def train(results, scene, mdl_path, vgg_weights_path, method_name, category):\n",
        "    img_shape = results[0][0].shape # (height, width, channel)\n",
        "        \n",
        "    model = initModel_S(lr, reg, img_shape, scene, vgg_weights_path)\n",
        "    \n",
        "    chk = keras.callbacks.ModelCheckpoint(mdl_path, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "    redu = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=reduce_factor, patience=num_patience, verbose=1, mode='auto')\n",
        "    early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=0, mode='auto')\n",
        "\n",
        "    t0=time.time()\n",
        "    model.fit(results[0], results[1], validation_split=val_split, epochs=max_epochs, batch_size=batch_size, \n",
        "              callbacks=[redu, early], verbose=1, class_weight=results[2], shuffle = True)\n",
        "    print (\"training time:\",category, \">\", scene,  round(time.time()-t0, 3), \"s\")\n",
        "    model.save(mdl_path)\n",
        "        \n",
        "    del model, results, chk, redu, early"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCEj_p2wxZkc"
      },
      "source": [
        "def VGG16(x): \n",
        "  # Block 1\n",
        "  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format='channels_last')(x)\n",
        "  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "  x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "    \n",
        "  # Block 2\n",
        "  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "  x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "    \n",
        "  # Block 3\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    \n",
        "  # Block 4\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "  x = Dropout(0.5, name='dr1')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "  x = Dropout(0.5, name='dr2')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "  x = Dropout(0.5, name='dr3')(x)\n",
        "        \n",
        "  return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmM7DkBIx0ks"
      },
      "source": [
        "def transposedConv(x, reg):\n",
        "  # block 5\n",
        "  x = Conv2DTranspose(64, (1, 1), activation='relu', padding='same', name='block5_tconv1', \n",
        "                                                kernel_regularizer=regularizers.l2(reg))(x)\n",
        "  x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', name='block5_tconv2')(x)\n",
        "  x = Conv2DTranspose(512, (1, 1), activation='relu', padding='same', name='block5_tconv3')(x)\n",
        "        \n",
        "  # block 6\n",
        "  x = Conv2DTranspose(64, (1, 1), activation='relu', padding='same', name='block6_tconv1', \n",
        "                                                kernel_regularizer=regularizers.l2(reg))(x)\n",
        "  x = Conv2DTranspose(64, (5, 5), strides=(2, 2), activation='relu', padding='same', name='block6_tconv2')(x)\n",
        "  x = Conv2DTranspose(256, (1, 1), activation='relu', padding='same', name='block6_tconv3')(x)\n",
        "        \n",
        "  # block 7\n",
        "  x = Conv2DTranspose(64, (1, 1), activation='relu', padding='same', name='block7_tconv1', \n",
        "                                                kernel_regularizer=regularizers.l2(reg))(x)\n",
        "  x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', name='block7_tconv2')(x)\n",
        "  x = Conv2DTranspose(128, (1, 1), activation='relu', padding='same', name='block7_tconv3')(x)\n",
        "        \n",
        "  # block 8\n",
        "  x = Conv2DTranspose(64, (5, 5), strides=(2, 2), activation='relu', padding='same', name='block8_conv1', \n",
        "                                                kernel_regularizer=regularizers.l2(reg))(x)\n",
        "        \n",
        "  # block 9\n",
        "  x = Conv2DTranspose(1, (1, 1), padding='same', name='block9_conv1')(x)\n",
        "  x = Activation('sigmoid')(x)\n",
        "        \n",
        "  return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNcuBEpPVtaA"
      },
      "source": [
        "def acc(y_true, y_pred):\n",
        "  void_label = -1.\n",
        "  y_pred = tf.reshape(y_pred, [-1])\n",
        "  y_true = tf.reshape(y_true, [-1])\n",
        "  idx = tf.where(tf.not_equal(y_true, tf.constant(void_label, dtype=tf.float32)))\n",
        "  y_pred = tf.gather_nd(y_pred, idx) \n",
        "  y_true = tf.gather_nd(y_true, idx)\n",
        "  return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RFlneAZi4rJ"
      },
      "source": [
        "def custom_f1(y_true, y_pred):    \n",
        "    void_label = -1.\n",
        "    y_pred = tf.reshape(y_pred, [-1])\n",
        "    y_true = tf.reshape(y_true, [-1])\n",
        "    idx = tf.where(tf.not_equal(y_true, tf.constant(void_label, dtype=tf.float32)))\n",
        "    y_pred = tf.gather_nd(y_pred, idx) \n",
        "    y_true = tf.gather_nd(y_true, idx)\n",
        "    \n",
        "    def recall_m(y_true, y_pred):\n",
        "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        \n",
        "        recall = TP / (Positives+K.epsilon())    \n",
        "        return recall \n",
        "    \n",
        "    \n",
        "    def precision_m(y_true, y_pred):\n",
        "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    \n",
        "        precision = TP / (Pred_Positives+K.epsilon())\n",
        "        return precision \n",
        "    \n",
        "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
        "    \n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwILdo0KVkox"
      },
      "source": [
        "#Loss function\n",
        "def loss(y_true, y_pred):\n",
        "  void_label = -1.\n",
        "  y_pred = K.reshape(y_pred, [-1])\n",
        "  y_true = K.reshape(y_true, [-1])\n",
        "  idx = tf.where(tf.not_equal(y_true, tf.constant(void_label, dtype=tf.float32)))\n",
        "  y_pred = tf.gather_nd(y_pred, idx) \n",
        "  y_true = tf.gather_nd(y_true, idx)\n",
        "  return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTgdOo8nPh8r"
      },
      "source": [
        "def FPM(x):\n",
        "  x1 = MaxPooling2D((2, 2), strides=(1,1), padding='same')(x)\n",
        "  x1 = Conv2D(64, (1, 1), padding='same')(x1)\n",
        "        \n",
        "  x2 = Conv2D(64, (3, 3), padding='same')(x)\n",
        "        \n",
        "  x3 = Conv2D(64, (3, 3), padding='same', dilation_rate=4)(x)\n",
        "        \n",
        "  x4 = Conv2D(64, (3, 3), padding='same', dilation_rate=8)(x)\n",
        "        \n",
        "  x5 = Conv2D(64, (3, 3), padding='same', dilation_rate=16)(x)\n",
        "        \n",
        "  x = keras.layers.concatenate([x1, x2, x3, x4, x5], axis=-1)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = SpatialDropout2D(0.25)(x)\n",
        "  return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fY_Ge27o0Co"
      },
      "source": [
        "#class MyUpSampling2D(Layer):\n",
        "    \n",
        "#    #@interfaces.legacy_upsampling2d_support\n",
        "#    def __init__(self, size=(2, 2), num_pixels = (0, 0), data_format='channels_last', method_name='FgSegNet_S', **kwargs):\n",
        "#        super(MyUpSampling2D, self).__init__(**kwargs)\n",
        "#        self.data_format = K.normalize_data_format(data_format)\n",
        "#        self.size = conv_utils.normalize_tuple(size, 2, 'size')\n",
        "#        self.input_spec = InputSpec(ndim=4)\n",
        "#        self.num_pixels = num_pixels\n",
        "#        self.method_name = method_name\n",
        "#\n",
        "#    def compute_output_shape(self, input_shape):\n",
        "#        if self.data_format == 'channels_last':\n",
        "#            height = self.size[0] * input_shape[1] + self.num_pixels[0] if input_shape[1] is not None else None\n",
        "#            width = self.size[1] * input_shape[2] + self.num_pixels[1] if input_shape[2] is not None else None\n",
        "#            return (input_shape[0], height, width, input_shape[3])\n",
        "#        \n",
        "#        else:\n",
        "#            raise ValueError('Invalid data_format:', self.data_format)\n",
        "#        \n",
        "#    def call(self, inputs):\n",
        "#        return resize_images(inputs, self.size[0], self.size[1], self.data_format, self.num_pixels, self.method_name)\n",
        "#\n",
        "#    def get_config(self):\n",
        "#        config = {'size': self.size,\n",
        "#                  'data_format': self.data_format,\n",
        "#                  'num_pixels': self.num_pixels}\n",
        "#        base_config = super(MyUpSampling2D, self).get_config()\n",
        "#        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiLDMZxxP6kj"
      },
      "source": [
        "def initModel_S(lr, reg, img_shape, scene, vgg_weights_path):\n",
        "  assert len(img_shape)==3\n",
        "  h, w, d = img_shape\n",
        "        \n",
        "  input_1 = Input(shape=(h, w, d), name='input')\n",
        "  vgg_layer_output = VGG16(input_1)\n",
        "  model = Model(inputs=input_1, outputs=vgg_layer_output, name='model')\n",
        "  #model.summary()\n",
        "  model.load_weights(vgg_weights_path, by_name=True)\n",
        "        \n",
        "  unfreeze_layers = ['block4_conv1','block4_conv2', 'block4_conv3']\n",
        "  for layer in model.layers:\n",
        "    if(layer.name not in unfreeze_layers):\n",
        "      layer.trainable = False\n",
        "                \n",
        "  x = model.output\n",
        "        \n",
        "  #x1_ups = {'streetCornerAtNight':(0,1), 'tramStation':(1,0), 'turbulence2':(1,0)}\n",
        "  #for key, val in x1_ups.items():\n",
        "  #  if scene==key:\n",
        "      # upscale by adding number of pixels to each dim.\n",
        "  #    x = MyUpSampling2D(size=(1,1), num_pixels=val)(x)\n",
        "  #    break\n",
        "                \n",
        "  x = FPM(x)\n",
        "  x = transposedConv(x, reg)\n",
        "        \n",
        "      \n",
        "  vision_model = Model(inputs=input_1, outputs=x, name='vision_model')\n",
        "  opt = keras.optimizers.RMSprop(lr = lr, rho=0.9, epsilon=1e-08, decay=0.)\n",
        "        \n",
        "  c_loss = loss\n",
        "  c_acc = acc\n",
        "  c_custom_f1 = custom_f1\n",
        "            \n",
        "  vision_model.compile(loss=c_loss, optimizer=opt, metrics=[c_custom_f1, c_acc])\n",
        "  vision_model.summary()\n",
        "  return vision_model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zv6aIxVsYrU"
      },
      "source": [
        "# Main Function\n",
        "# dataset for ablative experiment\n",
        "dataset = {\n",
        "            'baseline':['highway'],\n",
        "            'cameraJitter':['badminton'],\n",
        "            'badWeather':['skating'],\n",
        "            'dynamicBackground':['boats'],\n",
        "            'intermittentObjectMotion':['abandonedBox'],\n",
        "            'lowFramerate':['port_0_17fps'],\n",
        "            'nightVideos':['bridgeEntry'],\n",
        "            'PTZ':['continuousPan'],\n",
        "            'shadow':['backdoor'],\n",
        "            'thermal':['corridor'],\n",
        "            'turbulence':['turbulence0']\n",
        "}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dVhwnMesc_M"
      },
      "source": [
        "method_name = 'ModelB1' \n",
        "\n",
        "num_frames = 50 # default 50 frames\n",
        "reduce_factor = 0.1\n",
        "num_patience = 6\n",
        "lr = 1e-4\n",
        "reg=5e-4\n",
        "max_epochs = 50\n",
        "val_split = 0.2 #Assumed. For num_frames = 50; 40 frames will be used for training and 10 frames will be used for validation\n",
        "batch_size = 1 #Assumed to be 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWKHRcG2u--t"
      },
      "source": [
        "main_dir = os.path.join('/content/drive/MyDrive/FgSegNet', method_name)\n",
        "main_mdl_dir = os.path.join(main_dir, 'CDnet', 'models' + str(num_frames))\n",
        "vgg_weights_path = '/content/drive/MyDrive/FgSegNet/FgSegNet/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sEII-_WvGxk",
        "outputId": "cb41089a-955f-4db9-f59b-3b9d61754420"
      },
      "source": [
        "for category, scene_list in dataset.items():\n",
        "    \n",
        "    mdl_dir = os.path.join(main_mdl_dir, category)\n",
        "    if not os.path.exists(mdl_dir):\n",
        "        os.makedirs(mdl_dir)\n",
        "        \n",
        "    for scene in scene_list:\n",
        "        print ('Training ->>> ' + category + ' / ' + scene)\n",
        "        \n",
        "        # training frame path and dataset2014 path\n",
        "        train_dir = os.path.join('/content/drive/MyDrive/FgSegNet', 'FgSegNet_dataset2014', category, scene + str(num_frames))\n",
        "        dataset_dir = os.path.join('/content/drive/MyDrive/FgSegNet', 'CDnet2014_dataset', category, scene)\n",
        "        results = generateData(train_dir, dataset_dir, scene, method_name)\n",
        "        \n",
        "        mdl_path = os.path.join(mdl_dir, 'mdl_' + scene + '.h5')\n",
        "        train(results, scene, mdl_path, vgg_weights_path, method_name, category)\n",
        "        del results"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ->>> baseline / highway\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 64)   32832       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 320)  0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 320)  1280        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 320)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_1 (SpatialDro (None, 64, 64, 320)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 6s 158ms/step - loss: 0.4421 - custom_f1: 0.0038 - acc: 0.8883 - val_loss: 0.2779 - val_custom_f1: 0.0000e+00 - val_acc: 0.9046\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.2610 - custom_f1: 0.4160 - acc: 0.9354 - val_loss: 0.2384 - val_custom_f1: 0.9127 - val_acc: 0.9848\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.2219 - custom_f1: 0.9289 - acc: 0.9864 - val_loss: 0.1718 - val_custom_f1: 0.9633 - val_acc: 0.9929\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1645 - custom_f1: 0.9617 - acc: 0.9922 - val_loss: 0.1571 - val_custom_f1: 0.9623 - val_acc: 0.9927\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1494 - custom_f1: 0.9663 - acc: 0.9932 - val_loss: 0.1439 - val_custom_f1: 0.9670 - val_acc: 0.9935\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1381 - custom_f1: 0.9678 - acc: 0.9936 - val_loss: 0.1316 - val_custom_f1: 0.9705 - val_acc: 0.9943\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1274 - custom_f1: 0.9700 - acc: 0.9940 - val_loss: 0.1231 - val_custom_f1: 0.9687 - val_acc: 0.9940\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1179 - custom_f1: 0.9706 - acc: 0.9941 - val_loss: 0.1157 - val_custom_f1: 0.9672 - val_acc: 0.9938\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1089 - custom_f1: 0.9719 - acc: 0.9944 - val_loss: 0.1040 - val_custom_f1: 0.9744 - val_acc: 0.9951\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1014 - custom_f1: 0.9720 - acc: 0.9944 - val_loss: 0.1026 - val_custom_f1: 0.9666 - val_acc: 0.9935\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0939 - custom_f1: 0.9728 - acc: 0.9946 - val_loss: 0.0907 - val_custom_f1: 0.9728 - val_acc: 0.9947\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0874 - custom_f1: 0.9732 - acc: 0.9946 - val_loss: 0.0840 - val_custom_f1: 0.9741 - val_acc: 0.9950\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0813 - custom_f1: 0.9743 - acc: 0.9949 - val_loss: 0.0801 - val_custom_f1: 0.9723 - val_acc: 0.9946\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0758 - custom_f1: 0.9745 - acc: 0.9949 - val_loss: 0.0731 - val_custom_f1: 0.9748 - val_acc: 0.9951\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0706 - custom_f1: 0.9753 - acc: 0.9951 - val_loss: 0.0706 - val_custom_f1: 0.9720 - val_acc: 0.9946\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0664 - custom_f1: 0.9745 - acc: 0.9949 - val_loss: 0.0642 - val_custom_f1: 0.9747 - val_acc: 0.9952\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0619 - custom_f1: 0.9754 - acc: 0.9951 - val_loss: 0.0610 - val_custom_f1: 0.9744 - val_acc: 0.9950\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0582 - custom_f1: 0.9756 - acc: 0.9951 - val_loss: 0.0561 - val_custom_f1: 0.9774 - val_acc: 0.9958\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0544 - custom_f1: 0.9766 - acc: 0.9953 - val_loss: 0.0530 - val_custom_f1: 0.9758 - val_acc: 0.9954\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0514 - custom_f1: 0.9765 - acc: 0.9953 - val_loss: 0.0521 - val_custom_f1: 0.9714 - val_acc: 0.9947\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0488 - custom_f1: 0.9765 - acc: 0.9953 - val_loss: 0.0475 - val_custom_f1: 0.9771 - val_acc: 0.9957\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0460 - custom_f1: 0.9777 - acc: 0.9955 - val_loss: 0.0464 - val_custom_f1: 0.9745 - val_acc: 0.9951\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0438 - custom_f1: 0.9772 - acc: 0.9955 - val_loss: 0.0432 - val_custom_f1: 0.9767 - val_acc: 0.9956\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0412 - custom_f1: 0.9786 - acc: 0.9957 - val_loss: 0.0408 - val_custom_f1: 0.9778 - val_acc: 0.9958\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0399 - custom_f1: 0.9777 - acc: 0.9955 - val_loss: 0.0409 - val_custom_f1: 0.9754 - val_acc: 0.9952\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0383 - custom_f1: 0.9770 - acc: 0.9954 - val_loss: 0.0380 - val_custom_f1: 0.9762 - val_acc: 0.9955\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0359 - custom_f1: 0.9792 - acc: 0.9959 - val_loss: 0.0361 - val_custom_f1: 0.9772 - val_acc: 0.9957\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0348 - custom_f1: 0.9785 - acc: 0.9957 - val_loss: 0.0352 - val_custom_f1: 0.9769 - val_acc: 0.9957\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0335 - custom_f1: 0.9788 - acc: 0.9957 - val_loss: 0.0339 - val_custom_f1: 0.9768 - val_acc: 0.9956\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0319 - custom_f1: 0.9795 - acc: 0.9959 - val_loss: 0.0330 - val_custom_f1: 0.9769 - val_acc: 0.9955\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0304 - custom_f1: 0.9805 - acc: 0.9961 - val_loss: 0.0332 - val_custom_f1: 0.9748 - val_acc: 0.9951\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0294 - custom_f1: 0.9799 - acc: 0.9960 - val_loss: 0.0311 - val_custom_f1: 0.9767 - val_acc: 0.9955\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0281 - custom_f1: 0.9808 - acc: 0.9962 - val_loss: 0.0303 - val_custom_f1: 0.9759 - val_acc: 0.9955\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0275 - custom_f1: 0.9807 - acc: 0.9961 - val_loss: 0.0285 - val_custom_f1: 0.9778 - val_acc: 0.9958\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0270 - custom_f1: 0.9795 - acc: 0.9959 - val_loss: 0.0280 - val_custom_f1: 0.9779 - val_acc: 0.9958\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0259 - custom_f1: 0.9810 - acc: 0.9962 - val_loss: 0.0276 - val_custom_f1: 0.9784 - val_acc: 0.9959\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0250 - custom_f1: 0.9810 - acc: 0.9962 - val_loss: 0.0293 - val_custom_f1: 0.9743 - val_acc: 0.9950\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0243 - custom_f1: 0.9813 - acc: 0.9962 - val_loss: 0.0261 - val_custom_f1: 0.9777 - val_acc: 0.9958\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0236 - custom_f1: 0.9815 - acc: 0.9963 - val_loss: 0.0252 - val_custom_f1: 0.9780 - val_acc: 0.9958\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0233 - custom_f1: 0.9805 - acc: 0.9961 - val_loss: 0.0247 - val_custom_f1: 0.9779 - val_acc: 0.9958\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0225 - custom_f1: 0.9816 - acc: 0.9963 - val_loss: 0.0245 - val_custom_f1: 0.9784 - val_acc: 0.9959\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0223 - custom_f1: 0.9812 - acc: 0.9962 - val_loss: 0.0252 - val_custom_f1: 0.9772 - val_acc: 0.9956\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0216 - custom_f1: 0.9811 - acc: 0.9962 - val_loss: 0.0246 - val_custom_f1: 0.9773 - val_acc: 0.9956\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0213 - custom_f1: 0.9814 - acc: 0.9963 - val_loss: 0.0233 - val_custom_f1: 0.9755 - val_acc: 0.9955\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0206 - custom_f1: 0.9823 - acc: 0.9965 - val_loss: 0.0232 - val_custom_f1: 0.9760 - val_acc: 0.9955\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0202 - custom_f1: 0.9819 - acc: 0.9964 - val_loss: 0.0219 - val_custom_f1: 0.9780 - val_acc: 0.9959\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0196 - custom_f1: 0.9821 - acc: 0.9964 - val_loss: 0.0235 - val_custom_f1: 0.9770 - val_acc: 0.9956\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0190 - custom_f1: 0.9830 - acc: 0.9966 - val_loss: 0.0220 - val_custom_f1: 0.9770 - val_acc: 0.9956\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0190 - custom_f1: 0.9817 - acc: 0.9963 - val_loss: 0.0223 - val_custom_f1: 0.9734 - val_acc: 0.9951\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0182 - custom_f1: 0.9832 - acc: 0.9967 - val_loss: 0.0209 - val_custom_f1: 0.9781 - val_acc: 0.9959\n",
            "training time: baseline > highway 95.273 s\n",
            "Training ->>> cameraJitter / badminton\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 64)   32832       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 320)  0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 320)  1280        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 320)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_2 (SpatialDro (None, 64, 64, 320)  0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.3851 - custom_f1: 0.0021 - acc: 0.9525 - val_loss: 0.2327 - val_custom_f1: 0.0000e+00 - val_acc: 0.9666\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.2150 - custom_f1: 3.0848e-04 - acc: 0.9694 - val_loss: 0.2035 - val_custom_f1: 0.2770 - val_acc: 0.9728\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1897 - custom_f1: 0.4290 - acc: 0.9783 - val_loss: 0.1882 - val_custom_f1: 0.8113 - val_acc: 0.9873\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1691 - custom_f1: 0.7267 - acc: 0.9871 - val_loss: 0.1641 - val_custom_f1: 0.8240 - val_acc: 0.9882\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1508 - custom_f1: 0.8323 - acc: 0.9907 - val_loss: 0.1457 - val_custom_f1: 0.8561 - val_acc: 0.9896\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1332 - custom_f1: 0.8572 - acc: 0.9913 - val_loss: 0.1295 - val_custom_f1: 0.8614 - val_acc: 0.9902\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1217 - custom_f1: 0.8676 - acc: 0.9920 - val_loss: 0.1197 - val_custom_f1: 0.8665 - val_acc: 0.9911\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1128 - custom_f1: 0.8723 - acc: 0.9924 - val_loss: 0.1176 - val_custom_f1: 0.8450 - val_acc: 0.9886\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1055 - custom_f1: 0.8752 - acc: 0.9926 - val_loss: 0.1034 - val_custom_f1: 0.8791 - val_acc: 0.9918\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0984 - custom_f1: 0.8783 - acc: 0.9928 - val_loss: 0.0975 - val_custom_f1: 0.8787 - val_acc: 0.9916\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0914 - custom_f1: 0.8839 - acc: 0.9932 - val_loss: 0.0917 - val_custom_f1: 0.8756 - val_acc: 0.9914\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0859 - custom_f1: 0.8864 - acc: 0.9933 - val_loss: 0.0876 - val_custom_f1: 0.8723 - val_acc: 0.9910\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0799 - custom_f1: 0.8908 - acc: 0.9935 - val_loss: 0.0799 - val_custom_f1: 0.8868 - val_acc: 0.9923\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0749 - custom_f1: 0.8892 - acc: 0.9935 - val_loss: 0.0780 - val_custom_f1: 0.8748 - val_acc: 0.9913\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0705 - custom_f1: 0.8905 - acc: 0.9935 - val_loss: 0.0728 - val_custom_f1: 0.8797 - val_acc: 0.9916\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0663 - custom_f1: 0.8937 - acc: 0.9937 - val_loss: 0.0674 - val_custom_f1: 0.8857 - val_acc: 0.9921\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0622 - custom_f1: 0.8982 - acc: 0.9940 - val_loss: 0.0654 - val_custom_f1: 0.8808 - val_acc: 0.9917\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0585 - custom_f1: 0.8967 - acc: 0.9940 - val_loss: 0.0597 - val_custom_f1: 0.8927 - val_acc: 0.9928\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0558 - custom_f1: 0.8988 - acc: 0.9940 - val_loss: 0.0575 - val_custom_f1: 0.8920 - val_acc: 0.9925\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0525 - custom_f1: 0.9022 - acc: 0.9942 - val_loss: 0.0547 - val_custom_f1: 0.8920 - val_acc: 0.9927\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0504 - custom_f1: 0.8982 - acc: 0.9940 - val_loss: 0.0516 - val_custom_f1: 0.8957 - val_acc: 0.9932\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0477 - custom_f1: 0.9038 - acc: 0.9943 - val_loss: 0.0496 - val_custom_f1: 0.8946 - val_acc: 0.9931\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0456 - custom_f1: 0.9042 - acc: 0.9943 - val_loss: 0.0494 - val_custom_f1: 0.8876 - val_acc: 0.9923\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0438 - custom_f1: 0.9027 - acc: 0.9943 - val_loss: 0.0455 - val_custom_f1: 0.8920 - val_acc: 0.9934\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0416 - custom_f1: 0.9077 - acc: 0.9945 - val_loss: 0.0450 - val_custom_f1: 0.8931 - val_acc: 0.9927\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0404 - custom_f1: 0.9027 - acc: 0.9943 - val_loss: 0.0428 - val_custom_f1: 0.8946 - val_acc: 0.9930\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0387 - custom_f1: 0.9073 - acc: 0.9946 - val_loss: 0.0405 - val_custom_f1: 0.9000 - val_acc: 0.9936\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0371 - custom_f1: 0.9099 - acc: 0.9947 - val_loss: 0.0413 - val_custom_f1: 0.8900 - val_acc: 0.9927\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0355 - custom_f1: 0.9118 - acc: 0.9948 - val_loss: 0.0414 - val_custom_f1: 0.8860 - val_acc: 0.9920\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0348 - custom_f1: 0.9098 - acc: 0.9947 - val_loss: 0.0379 - val_custom_f1: 0.8976 - val_acc: 0.9931\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0335 - custom_f1: 0.9123 - acc: 0.9948 - val_loss: 0.0362 - val_custom_f1: 0.8946 - val_acc: 0.9936\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0326 - custom_f1: 0.9083 - acc: 0.9947 - val_loss: 0.0356 - val_custom_f1: 0.8997 - val_acc: 0.9933\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0316 - custom_f1: 0.9119 - acc: 0.9949 - val_loss: 0.0341 - val_custom_f1: 0.9038 - val_acc: 0.9936\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0307 - custom_f1: 0.9143 - acc: 0.9949 - val_loss: 0.0346 - val_custom_f1: 0.8949 - val_acc: 0.9929\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0297 - custom_f1: 0.9148 - acc: 0.9950 - val_loss: 0.0324 - val_custom_f1: 0.9033 - val_acc: 0.9938\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0288 - custom_f1: 0.9161 - acc: 0.9951 - val_loss: 0.0367 - val_custom_f1: 0.8845 - val_acc: 0.9919\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0285 - custom_f1: 0.9146 - acc: 0.9949 - val_loss: 0.0313 - val_custom_f1: 0.9033 - val_acc: 0.9938\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0277 - custom_f1: 0.9169 - acc: 0.9951 - val_loss: 0.0303 - val_custom_f1: 0.9041 - val_acc: 0.9939\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0270 - custom_f1: 0.9175 - acc: 0.9952 - val_loss: 0.0369 - val_custom_f1: 0.8772 - val_acc: 0.9913\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0266 - custom_f1: 0.9162 - acc: 0.9951 - val_loss: 0.0294 - val_custom_f1: 0.9048 - val_acc: 0.9938\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0258 - custom_f1: 0.9193 - acc: 0.9952 - val_loss: 0.0292 - val_custom_f1: 0.9019 - val_acc: 0.9935\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0253 - custom_f1: 0.9194 - acc: 0.9952 - val_loss: 0.0282 - val_custom_f1: 0.9054 - val_acc: 0.9939\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0248 - custom_f1: 0.9206 - acc: 0.9954 - val_loss: 0.0277 - val_custom_f1: 0.9046 - val_acc: 0.9939\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0240 - custom_f1: 0.9225 - acc: 0.9955 - val_loss: 0.0279 - val_custom_f1: 0.9017 - val_acc: 0.9936\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0238 - custom_f1: 0.9216 - acc: 0.9954 - val_loss: 0.0267 - val_custom_f1: 0.9052 - val_acc: 0.9940\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0233 - custom_f1: 0.9198 - acc: 0.9954 - val_loss: 0.0275 - val_custom_f1: 0.8993 - val_acc: 0.9933\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0226 - custom_f1: 0.9229 - acc: 0.9955 - val_loss: 0.0280 - val_custom_f1: 0.9004 - val_acc: 0.9934\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0223 - custom_f1: 0.9241 - acc: 0.9955 - val_loss: 0.0285 - val_custom_f1: 0.8950 - val_acc: 0.9928\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0221 - custom_f1: 0.9234 - acc: 0.9955 - val_loss: 0.0254 - val_custom_f1: 0.9072 - val_acc: 0.9941\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0216 - custom_f1: 0.9249 - acc: 0.9956 - val_loss: 0.0267 - val_custom_f1: 0.9011 - val_acc: 0.9933\n",
            "training time: cameraJitter > badminton 92.32 s\n",
            "Training ->>> badWeather / skating\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 64, 64, 320)  0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 320)  1280        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 320)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_3 (SpatialDro (None, 64, 64, 320)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.4445 - custom_f1: 1.1250e-04 - acc: 0.8705 - val_loss: 0.5363 - val_custom_f1: 0.0000e+00 - val_acc: 0.8765\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.2966 - custom_f1: 0.5047 - acc: 0.9182 - val_loss: 0.3021 - val_custom_f1: 0.6673 - val_acc: 0.9438\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.2649 - custom_f1: 0.8836 - acc: 0.9739 - val_loss: 0.2909 - val_custom_f1: 0.8016 - val_acc: 0.9624\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1997 - custom_f1: 0.9321 - acc: 0.9834 - val_loss: 0.1994 - val_custom_f1: 0.9109 - val_acc: 0.9810\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1781 - custom_f1: 0.9442 - acc: 0.9862 - val_loss: 0.1776 - val_custom_f1: 0.9353 - val_acc: 0.9841\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1649 - custom_f1: 0.9495 - acc: 0.9876 - val_loss: 0.1696 - val_custom_f1: 0.9286 - val_acc: 0.9828\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1550 - custom_f1: 0.9527 - acc: 0.9884 - val_loss: 0.1574 - val_custom_f1: 0.9384 - val_acc: 0.9848\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1441 - custom_f1: 0.9577 - acc: 0.9898 - val_loss: 0.1560 - val_custom_f1: 0.9291 - val_acc: 0.9831\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1360 - custom_f1: 0.9593 - acc: 0.9903 - val_loss: 0.1608 - val_custom_f1: 0.9150 - val_acc: 0.9792\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1282 - custom_f1: 0.9618 - acc: 0.9908 - val_loss: 0.1500 - val_custom_f1: 0.9233 - val_acc: 0.9808\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1208 - custom_f1: 0.9631 - acc: 0.9911 - val_loss: 0.1280 - val_custom_f1: 0.9420 - val_acc: 0.9870\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1144 - custom_f1: 0.9640 - acc: 0.9913 - val_loss: 0.1291 - val_custom_f1: 0.9367 - val_acc: 0.9847\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1093 - custom_f1: 0.9642 - acc: 0.9913 - val_loss: 0.1168 - val_custom_f1: 0.9456 - val_acc: 0.9870\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1038 - custom_f1: 0.9655 - acc: 0.9917 - val_loss: 0.1063 - val_custom_f1: 0.9557 - val_acc: 0.9897\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0980 - custom_f1: 0.9671 - acc: 0.9921 - val_loss: 0.1076 - val_custom_f1: 0.9459 - val_acc: 0.9870\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0933 - custom_f1: 0.9681 - acc: 0.9924 - val_loss: 0.0988 - val_custom_f1: 0.9534 - val_acc: 0.9892\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0895 - custom_f1: 0.9672 - acc: 0.9922 - val_loss: 0.0940 - val_custom_f1: 0.9547 - val_acc: 0.9895\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0845 - custom_f1: 0.9697 - acc: 0.9928 - val_loss: 0.0947 - val_custom_f1: 0.9474 - val_acc: 0.9875\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0809 - custom_f1: 0.9702 - acc: 0.9928 - val_loss: 0.0891 - val_custom_f1: 0.9503 - val_acc: 0.9883\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0770 - custom_f1: 0.9705 - acc: 0.9930 - val_loss: 0.0951 - val_custom_f1: 0.9364 - val_acc: 0.9851\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0741 - custom_f1: 0.9702 - acc: 0.9930 - val_loss: 0.0805 - val_custom_f1: 0.9565 - val_acc: 0.9898\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0709 - custom_f1: 0.9712 - acc: 0.9931 - val_loss: 0.0814 - val_custom_f1: 0.9496 - val_acc: 0.9882\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0688 - custom_f1: 0.9715 - acc: 0.9932 - val_loss: 0.0760 - val_custom_f1: 0.9541 - val_acc: 0.9897\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0655 - custom_f1: 0.9712 - acc: 0.9933 - val_loss: 0.0764 - val_custom_f1: 0.9521 - val_acc: 0.9887\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0628 - custom_f1: 0.9732 - acc: 0.9935 - val_loss: 0.0726 - val_custom_f1: 0.9539 - val_acc: 0.9890\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0612 - custom_f1: 0.9724 - acc: 0.9932 - val_loss: 0.0683 - val_custom_f1: 0.9565 - val_acc: 0.9902\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0596 - custom_f1: 0.9715 - acc: 0.9932 - val_loss: 0.0668 - val_custom_f1: 0.9559 - val_acc: 0.9901\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0572 - custom_f1: 0.9739 - acc: 0.9936 - val_loss: 0.0695 - val_custom_f1: 0.9476 - val_acc: 0.9876\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0550 - custom_f1: 0.9740 - acc: 0.9937 - val_loss: 0.0666 - val_custom_f1: 0.9479 - val_acc: 0.9890\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0528 - custom_f1: 0.9746 - acc: 0.9938 - val_loss: 0.0646 - val_custom_f1: 0.9526 - val_acc: 0.9891\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0520 - custom_f1: 0.9747 - acc: 0.9938 - val_loss: 0.0577 - val_custom_f1: 0.9608 - val_acc: 0.9912\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0501 - custom_f1: 0.9736 - acc: 0.9938 - val_loss: 0.0660 - val_custom_f1: 0.9469 - val_acc: 0.9874\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0486 - custom_f1: 0.9745 - acc: 0.9938 - val_loss: 0.0565 - val_custom_f1: 0.9573 - val_acc: 0.9901\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0467 - custom_f1: 0.9764 - acc: 0.9942 - val_loss: 0.0599 - val_custom_f1: 0.9527 - val_acc: 0.9888\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0456 - custom_f1: 0.9758 - acc: 0.9941 - val_loss: 0.0554 - val_custom_f1: 0.9549 - val_acc: 0.9900\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0445 - custom_f1: 0.9759 - acc: 0.9941 - val_loss: 0.0512 - val_custom_f1: 0.9607 - val_acc: 0.9912\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0434 - custom_f1: 0.9753 - acc: 0.9941 - val_loss: 0.0537 - val_custom_f1: 0.9571 - val_acc: 0.9907\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0427 - custom_f1: 0.9756 - acc: 0.9940 - val_loss: 0.0522 - val_custom_f1: 0.9557 - val_acc: 0.9902\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0407 - custom_f1: 0.9761 - acc: 0.9945 - val_loss: 0.0485 - val_custom_f1: 0.9609 - val_acc: 0.9910\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0403 - custom_f1: 0.9760 - acc: 0.9942 - val_loss: 0.0545 - val_custom_f1: 0.9513 - val_acc: 0.9884\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0389 - custom_f1: 0.9768 - acc: 0.9945 - val_loss: 0.0473 - val_custom_f1: 0.9609 - val_acc: 0.9909\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0381 - custom_f1: 0.9768 - acc: 0.9944 - val_loss: 0.0554 - val_custom_f1: 0.9490 - val_acc: 0.9879\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0369 - custom_f1: 0.9777 - acc: 0.9946 - val_loss: 0.0454 - val_custom_f1: 0.9604 - val_acc: 0.9912\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0356 - custom_f1: 0.9789 - acc: 0.9949 - val_loss: 0.0455 - val_custom_f1: 0.9611 - val_acc: 0.9910\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0355 - custom_f1: 0.9774 - acc: 0.9945 - val_loss: 0.0441 - val_custom_f1: 0.9613 - val_acc: 0.9912\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0346 - custom_f1: 0.9781 - acc: 0.9946 - val_loss: 0.0443 - val_custom_f1: 0.9588 - val_acc: 0.9909\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0339 - custom_f1: 0.9785 - acc: 0.9947 - val_loss: 0.0443 - val_custom_f1: 0.9601 - val_acc: 0.9909\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0330 - custom_f1: 0.9784 - acc: 0.9948 - val_loss: 0.0453 - val_custom_f1: 0.9568 - val_acc: 0.9898\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0331 - custom_f1: 0.9773 - acc: 0.9946 - val_loss: 0.0480 - val_custom_f1: 0.9539 - val_acc: 0.9889\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0324 - custom_f1: 0.9778 - acc: 0.9946 - val_loss: 0.0502 - val_custom_f1: 0.9506 - val_acc: 0.9882\n",
            "training time: badWeather > skating 94.728 s\n",
            "Training ->>> dynamicBackground / boats\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 64, 64, 320)  0           conv2d_16[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 320)  1280        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 64, 320)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_4 (SpatialDro (None, 64, 64, 320)  0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.3648 - custom_f1: 0.0037 - acc: 0.9518 - val_loss: 0.2165 - val_custom_f1: 0.0000e+00 - val_acc: 0.9658\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.2015 - custom_f1: 0.1100 - acc: 0.9695 - val_loss: 0.1920 - val_custom_f1: 0.6726 - val_acc: 0.9830\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1778 - custom_f1: 0.8234 - acc: 0.9903 - val_loss: 0.1673 - val_custom_f1: 0.9255 - val_acc: 0.9949\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1474 - custom_f1: 0.9370 - acc: 0.9959 - val_loss: 0.1382 - val_custom_f1: 0.9360 - val_acc: 0.9957\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1300 - custom_f1: 0.9444 - acc: 0.9964 - val_loss: 0.1262 - val_custom_f1: 0.9320 - val_acc: 0.9951\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1171 - custom_f1: 0.9516 - acc: 0.9968 - val_loss: 0.1126 - val_custom_f1: 0.9465 - val_acc: 0.9964\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1072 - custom_f1: 0.9509 - acc: 0.9968 - val_loss: 0.1032 - val_custom_f1: 0.9496 - val_acc: 0.9966\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0976 - custom_f1: 0.9530 - acc: 0.9969 - val_loss: 0.0941 - val_custom_f1: 0.9502 - val_acc: 0.9966\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0893 - custom_f1: 0.9523 - acc: 0.9969 - val_loss: 0.0872 - val_custom_f1: 0.9480 - val_acc: 0.9963\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0818 - custom_f1: 0.9551 - acc: 0.9971 - val_loss: 0.0831 - val_custom_f1: 0.9235 - val_acc: 0.9952\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0753 - custom_f1: 0.9537 - acc: 0.9970 - val_loss: 0.0737 - val_custom_f1: 0.9480 - val_acc: 0.9963\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0687 - custom_f1: 0.9569 - acc: 0.9972 - val_loss: 0.0679 - val_custom_f1: 0.9445 - val_acc: 0.9964\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0631 - custom_f1: 0.9574 - acc: 0.9972 - val_loss: 0.0620 - val_custom_f1: 0.9504 - val_acc: 0.9967\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0579 - custom_f1: 0.9572 - acc: 0.9973 - val_loss: 0.0575 - val_custom_f1: 0.9457 - val_acc: 0.9964\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0532 - custom_f1: 0.9585 - acc: 0.9973 - val_loss: 0.0535 - val_custom_f1: 0.9434 - val_acc: 0.9962\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0489 - custom_f1: 0.9595 - acc: 0.9974 - val_loss: 0.0495 - val_custom_f1: 0.9490 - val_acc: 0.9964\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0447 - custom_f1: 0.9622 - acc: 0.9976 - val_loss: 0.0444 - val_custom_f1: 0.9524 - val_acc: 0.9968\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0412 - custom_f1: 0.9611 - acc: 0.9975 - val_loss: 0.0413 - val_custom_f1: 0.9547 - val_acc: 0.9969\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0384 - custom_f1: 0.9612 - acc: 0.9975 - val_loss: 0.0384 - val_custom_f1: 0.9531 - val_acc: 0.9968\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0357 - custom_f1: 0.9618 - acc: 0.9975 - val_loss: 0.0358 - val_custom_f1: 0.9523 - val_acc: 0.9968\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0333 - custom_f1: 0.9615 - acc: 0.9975 - val_loss: 0.0344 - val_custom_f1: 0.9506 - val_acc: 0.9967\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0314 - custom_f1: 0.9600 - acc: 0.9974 - val_loss: 0.0336 - val_custom_f1: 0.9434 - val_acc: 0.9963\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0290 - custom_f1: 0.9632 - acc: 0.9976 - val_loss: 0.0300 - val_custom_f1: 0.9530 - val_acc: 0.9967\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0272 - custom_f1: 0.9633 - acc: 0.9976 - val_loss: 0.0277 - val_custom_f1: 0.9565 - val_acc: 0.9971\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0258 - custom_f1: 0.9641 - acc: 0.9977 - val_loss: 0.0273 - val_custom_f1: 0.9505 - val_acc: 0.9968\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0244 - custom_f1: 0.9634 - acc: 0.9976 - val_loss: 0.0275 - val_custom_f1: 0.9419 - val_acc: 0.9962\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0231 - custom_f1: 0.9643 - acc: 0.9977 - val_loss: 0.0261 - val_custom_f1: 0.9405 - val_acc: 0.9962\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0218 - custom_f1: 0.9657 - acc: 0.9978 - val_loss: 0.0230 - val_custom_f1: 0.9579 - val_acc: 0.9971\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0209 - custom_f1: 0.9643 - acc: 0.9977 - val_loss: 0.0226 - val_custom_f1: 0.9533 - val_acc: 0.9969\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0199 - custom_f1: 0.9649 - acc: 0.9977 - val_loss: 0.0212 - val_custom_f1: 0.9534 - val_acc: 0.9969\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0189 - custom_f1: 0.9650 - acc: 0.9978 - val_loss: 0.0247 - val_custom_f1: 0.9304 - val_acc: 0.9956\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0182 - custom_f1: 0.9673 - acc: 0.9979 - val_loss: 0.0208 - val_custom_f1: 0.9530 - val_acc: 0.9967\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0176 - custom_f1: 0.9664 - acc: 0.9979 - val_loss: 0.0199 - val_custom_f1: 0.9525 - val_acc: 0.9967\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0170 - custom_f1: 0.9664 - acc: 0.9978 - val_loss: 0.0183 - val_custom_f1: 0.9608 - val_acc: 0.9973\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0164 - custom_f1: 0.9661 - acc: 0.9978 - val_loss: 0.0186 - val_custom_f1: 0.9524 - val_acc: 0.9969\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0155 - custom_f1: 0.9696 - acc: 0.9981 - val_loss: 0.0175 - val_custom_f1: 0.9554 - val_acc: 0.9970\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0150 - custom_f1: 0.9692 - acc: 0.9981 - val_loss: 0.0173 - val_custom_f1: 0.9557 - val_acc: 0.9969\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0145 - custom_f1: 0.9698 - acc: 0.9981 - val_loss: 0.0163 - val_custom_f1: 0.9558 - val_acc: 0.9970\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0140 - custom_f1: 0.9696 - acc: 0.9981 - val_loss: 0.0170 - val_custom_f1: 0.9509 - val_acc: 0.9968\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0139 - custom_f1: 0.9677 - acc: 0.9980 - val_loss: 0.0164 - val_custom_f1: 0.9551 - val_acc: 0.9969\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0135 - custom_f1: 0.9698 - acc: 0.9980 - val_loss: 0.0152 - val_custom_f1: 0.9577 - val_acc: 0.9972\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0134 - custom_f1: 0.9671 - acc: 0.9979 - val_loss: 0.0167 - val_custom_f1: 0.9536 - val_acc: 0.9967\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0128 - custom_f1: 0.9688 - acc: 0.9980 - val_loss: 0.0146 - val_custom_f1: 0.9603 - val_acc: 0.9973\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0124 - custom_f1: 0.9691 - acc: 0.9980 - val_loss: 0.0145 - val_custom_f1: 0.9578 - val_acc: 0.9971\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0121 - custom_f1: 0.9720 - acc: 0.9982 - val_loss: 0.0139 - val_custom_f1: 0.9594 - val_acc: 0.9972\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0118 - custom_f1: 0.9692 - acc: 0.9980 - val_loss: 0.0156 - val_custom_f1: 0.9445 - val_acc: 0.9963\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0115 - custom_f1: 0.9714 - acc: 0.9982 - val_loss: 0.0141 - val_custom_f1: 0.9565 - val_acc: 0.9970\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0114 - custom_f1: 0.9704 - acc: 0.9981 - val_loss: 0.0145 - val_custom_f1: 0.9481 - val_acc: 0.9967\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0111 - custom_f1: 0.9702 - acc: 0.9981 - val_loss: 0.0135 - val_custom_f1: 0.9591 - val_acc: 0.9972\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0110 - custom_f1: 0.9694 - acc: 0.9980 - val_loss: 0.0140 - val_custom_f1: 0.9559 - val_acc: 0.9969\n",
            "training time: dynamicBackground > boats 94.458 s\n",
            "Training ->>> intermittentObjectMotion / abandonedBox\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 64, 64, 320)  0           conv2d_21[0][0]                  \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 320)  1280        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 320)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_5 (SpatialDro (None, 64, 64, 320)  0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.3706 - custom_f1: 0.0050 - acc: 0.9314 - val_loss: 0.2461 - val_custom_f1: 0.0000e+00 - val_acc: 0.9483\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.2347 - custom_f1: 0.1450 - acc: 0.9534 - val_loss: 0.2186 - val_custom_f1: 0.6177 - val_acc: 0.9700\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.2069 - custom_f1: 0.7622 - acc: 0.9796 - val_loss: 0.1983 - val_custom_f1: 0.8599 - val_acc: 0.9853\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1879 - custom_f1: 0.8404 - acc: 0.9828 - val_loss: 0.1733 - val_custom_f1: 0.8918 - val_acc: 0.9879\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1726 - custom_f1: 0.8726 - acc: 0.9859 - val_loss: 0.1646 - val_custom_f1: 0.8922 - val_acc: 0.9883\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1626 - custom_f1: 0.8681 - acc: 0.9859 - val_loss: 0.1553 - val_custom_f1: 0.8887 - val_acc: 0.9878\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1537 - custom_f1: 0.8741 - acc: 0.9862 - val_loss: 0.1472 - val_custom_f1: 0.8958 - val_acc: 0.9886\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1456 - custom_f1: 0.8799 - acc: 0.9874 - val_loss: 0.1428 - val_custom_f1: 0.8862 - val_acc: 0.9877\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.1390 - custom_f1: 0.8785 - acc: 0.9871 - val_loss: 0.1413 - val_custom_f1: 0.8682 - val_acc: 0.9863\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1327 - custom_f1: 0.8799 - acc: 0.9875 - val_loss: 0.1289 - val_custom_f1: 0.8823 - val_acc: 0.9867\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1252 - custom_f1: 0.8852 - acc: 0.9879 - val_loss: 0.1218 - val_custom_f1: 0.8993 - val_acc: 0.9888\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1218 - custom_f1: 0.8829 - acc: 0.9876 - val_loss: 0.1200 - val_custom_f1: 0.8846 - val_acc: 0.9880\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1155 - custom_f1: 0.8916 - acc: 0.9883 - val_loss: 0.1201 - val_custom_f1: 0.8709 - val_acc: 0.9866\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1105 - custom_f1: 0.8925 - acc: 0.9885 - val_loss: 0.1095 - val_custom_f1: 0.8917 - val_acc: 0.9882\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1054 - custom_f1: 0.8955 - acc: 0.9888 - val_loss: 0.1064 - val_custom_f1: 0.8870 - val_acc: 0.9876\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1014 - custom_f1: 0.8932 - acc: 0.9893 - val_loss: 0.1024 - val_custom_f1: 0.8875 - val_acc: 0.9879\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0988 - custom_f1: 0.8943 - acc: 0.9887 - val_loss: 0.0979 - val_custom_f1: 0.8964 - val_acc: 0.9886\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0951 - custom_f1: 0.8918 - acc: 0.9885 - val_loss: 0.1020 - val_custom_f1: 0.8524 - val_acc: 0.9851\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0905 - custom_f1: 0.8999 - acc: 0.9894 - val_loss: 0.0945 - val_custom_f1: 0.8899 - val_acc: 0.9883\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0873 - custom_f1: 0.9011 - acc: 0.9896 - val_loss: 0.0919 - val_custom_f1: 0.9031 - val_acc: 0.9896\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0856 - custom_f1: 0.9040 - acc: 0.9897 - val_loss: 0.0883 - val_custom_f1: 0.8941 - val_acc: 0.9886\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0823 - custom_f1: 0.9026 - acc: 0.9898 - val_loss: 0.0898 - val_custom_f1: 0.8898 - val_acc: 0.9883\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0813 - custom_f1: 0.8998 - acc: 0.9894 - val_loss: 0.0883 - val_custom_f1: 0.8925 - val_acc: 0.9887\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0782 - custom_f1: 0.9126 - acc: 0.9904 - val_loss: 0.0866 - val_custom_f1: 0.8998 - val_acc: 0.9894\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0749 - custom_f1: 0.9066 - acc: 0.9905 - val_loss: 0.0834 - val_custom_f1: 0.9038 - val_acc: 0.9898\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0733 - custom_f1: 0.9125 - acc: 0.9908 - val_loss: 0.0894 - val_custom_f1: 0.8847 - val_acc: 0.9880\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0705 - custom_f1: 0.9159 - acc: 0.9911 - val_loss: 0.0823 - val_custom_f1: 0.9062 - val_acc: 0.9898\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0691 - custom_f1: 0.9152 - acc: 0.9909 - val_loss: 0.0781 - val_custom_f1: 0.8989 - val_acc: 0.9892\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0676 - custom_f1: 0.9148 - acc: 0.9911 - val_loss: 0.0784 - val_custom_f1: 0.9043 - val_acc: 0.9899\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0653 - custom_f1: 0.9206 - acc: 0.9916 - val_loss: 0.0813 - val_custom_f1: 0.8877 - val_acc: 0.9877\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0645 - custom_f1: 0.9173 - acc: 0.9911 - val_loss: 0.0766 - val_custom_f1: 0.8996 - val_acc: 0.9894\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0629 - custom_f1: 0.9182 - acc: 0.9912 - val_loss: 0.0719 - val_custom_f1: 0.8980 - val_acc: 0.9894\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0608 - custom_f1: 0.9208 - acc: 0.9918 - val_loss: 0.0772 - val_custom_f1: 0.8997 - val_acc: 0.9895\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0600 - custom_f1: 0.9174 - acc: 0.9914 - val_loss: 0.0717 - val_custom_f1: 0.9085 - val_acc: 0.9902\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0590 - custom_f1: 0.9185 - acc: 0.9914 - val_loss: 0.0703 - val_custom_f1: 0.9002 - val_acc: 0.9894\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0573 - custom_f1: 0.9253 - acc: 0.9920 - val_loss: 0.0720 - val_custom_f1: 0.8939 - val_acc: 0.9889\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0561 - custom_f1: 0.9236 - acc: 0.9919 - val_loss: 0.0702 - val_custom_f1: 0.9073 - val_acc: 0.9900\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0554 - custom_f1: 0.9243 - acc: 0.9920 - val_loss: 0.0702 - val_custom_f1: 0.8889 - val_acc: 0.9883\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0536 - custom_f1: 0.9270 - acc: 0.9924 - val_loss: 0.0697 - val_custom_f1: 0.9034 - val_acc: 0.9898\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0532 - custom_f1: 0.9274 - acc: 0.9922 - val_loss: 0.0758 - val_custom_f1: 0.8857 - val_acc: 0.9880\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0521 - custom_f1: 0.9249 - acc: 0.9921 - val_loss: 0.0686 - val_custom_f1: 0.8856 - val_acc: 0.9878\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0514 - custom_f1: 0.9244 - acc: 0.9921 - val_loss: 0.0690 - val_custom_f1: 0.8985 - val_acc: 0.9893\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0502 - custom_f1: 0.9250 - acc: 0.9921 - val_loss: 0.0667 - val_custom_f1: 0.8933 - val_acc: 0.9887\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0496 - custom_f1: 0.9250 - acc: 0.9922 - val_loss: 0.0643 - val_custom_f1: 0.9065 - val_acc: 0.9900\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0474 - custom_f1: 0.9366 - acc: 0.9932 - val_loss: 0.0679 - val_custom_f1: 0.9016 - val_acc: 0.9896\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0472 - custom_f1: 0.9294 - acc: 0.9927 - val_loss: 0.0651 - val_custom_f1: 0.8964 - val_acc: 0.9891\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0473 - custom_f1: 0.9282 - acc: 0.9925 - val_loss: 0.0688 - val_custom_f1: 0.9001 - val_acc: 0.9894\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0456 - custom_f1: 0.9283 - acc: 0.9926 - val_loss: 0.0631 - val_custom_f1: 0.9052 - val_acc: 0.9898\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0455 - custom_f1: 0.9261 - acc: 0.9924 - val_loss: 0.0636 - val_custom_f1: 0.8994 - val_acc: 0.9892\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0448 - custom_f1: 0.9323 - acc: 0.9927 - val_loss: 0.0607 - val_custom_f1: 0.9007 - val_acc: 0.9894\n",
            "training time: intermittentObjectMotion > abandonedBox 95.619 s\n",
            "Training ->>> lowFramerate / port_0_17fps\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 64, 64, 320)  0           conv2d_26[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 320)  1280        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 64, 64, 320)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_6 (SpatialDro (None, 64, 64, 320)  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.3347 - custom_f1: 4.1763e-04 - acc: 0.9803 - val_loss: 0.1983 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1784 - custom_f1: 0.0000e+00 - acc: 0.9992 - val_loss: 0.1757 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1572 - custom_f1: 0.0000e+00 - acc: 0.9992 - val_loss: 0.1513 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1380 - custom_f1: 0.0000e+00 - acc: 0.9992 - val_loss: 0.1366 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1211 - custom_f1: 0.0000e+00 - acc: 0.9992 - val_loss: 0.1196 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1058 - custom_f1: 0.0000e+00 - acc: 0.9992 - val_loss: 0.1041 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0928 - custom_f1: 0.0000e+00 - acc: 0.9992 - val_loss: 0.0899 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0813 - custom_f1: 0.0000e+00 - acc: 0.9992 - val_loss: 0.0826 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0716 - custom_f1: 4.1322e-04 - acc: 0.9992 - val_loss: 0.0706 - val_custom_f1: 0.0021 - val_acc: 0.9989\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0627 - custom_f1: 0.0165 - acc: 0.9992 - val_loss: 0.0625 - val_custom_f1: 0.0360 - val_acc: 0.9989\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0549 - custom_f1: 0.0434 - acc: 0.9992 - val_loss: 0.0548 - val_custom_f1: 0.0348 - val_acc: 0.9989\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0480 - custom_f1: 0.0556 - acc: 0.9993 - val_loss: 0.0520 - val_custom_f1: 0.0000e+00 - val_acc: 0.9989\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0415 - custom_f1: 0.0632 - acc: 0.9993 - val_loss: 0.0433 - val_custom_f1: 0.0110 - val_acc: 0.9989\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0357 - custom_f1: 0.1234 - acc: 0.9993 - val_loss: 0.0383 - val_custom_f1: 0.0111 - val_acc: 0.9989\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0308 - custom_f1: 0.1113 - acc: 0.9993 - val_loss: 0.0323 - val_custom_f1: 0.0978 - val_acc: 0.9990\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0264 - custom_f1: 0.1213 - acc: 0.9994 - val_loss: 0.0282 - val_custom_f1: 0.1146 - val_acc: 0.9990\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0225 - custom_f1: 0.1707 - acc: 0.9994 - val_loss: 0.0259 - val_custom_f1: 0.0251 - val_acc: 0.9989\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0191 - custom_f1: 0.1659 - acc: 0.9994 - val_loss: 0.0218 - val_custom_f1: 0.1497 - val_acc: 0.9986\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0162 - custom_f1: 0.1660 - acc: 0.9994 - val_loss: 0.0190 - val_custom_f1: 0.1256 - val_acc: 0.9990\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0135 - custom_f1: 0.2138 - acc: 0.9995 - val_loss: 0.0166 - val_custom_f1: 0.1544 - val_acc: 0.9990\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0114 - custom_f1: 0.2194 - acc: 0.9995 - val_loss: 0.0148 - val_custom_f1: 0.1127 - val_acc: 0.9990\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0096 - custom_f1: 0.2118 - acc: 0.9995 - val_loss: 0.0142 - val_custom_f1: 0.0560 - val_acc: 0.9990\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0081 - custom_f1: 0.2254 - acc: 0.9995 - val_loss: 0.0134 - val_custom_f1: 0.0403 - val_acc: 0.9989\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0068 - custom_f1: 0.2324 - acc: 0.9995 - val_loss: 0.0103 - val_custom_f1: 0.0997 - val_acc: 0.9990\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0058 - custom_f1: 0.2307 - acc: 0.9995 - val_loss: 0.0090 - val_custom_f1: 0.2701 - val_acc: 0.9991\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0051 - custom_f1: 0.2605 - acc: 0.9995 - val_loss: 0.0088 - val_custom_f1: 0.2503 - val_acc: 0.9991\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0043 - custom_f1: 0.2695 - acc: 0.9995 - val_loss: 0.0077 - val_custom_f1: 0.2903 - val_acc: 0.9990\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0038 - custom_f1: 0.2570 - acc: 0.9995 - val_loss: 0.0079 - val_custom_f1: 0.1689 - val_acc: 0.9990\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0034 - custom_f1: 0.2870 - acc: 0.9995 - val_loss: 0.0078 - val_custom_f1: 0.2080 - val_acc: 0.9990\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0030 - custom_f1: 0.2879 - acc: 0.9995 - val_loss: 0.0081 - val_custom_f1: 0.1100 - val_acc: 0.9990\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0027 - custom_f1: 0.2573 - acc: 0.9995 - val_loss: 0.0078 - val_custom_f1: 0.1088 - val_acc: 0.9990\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0024 - custom_f1: 0.2954 - acc: 0.9996 - val_loss: 0.0073 - val_custom_f1: 0.1312 - val_acc: 0.9991\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0022 - custom_f1: 0.3199 - acc: 0.9996 - val_loss: 0.0065 - val_custom_f1: 0.3010 - val_acc: 0.9989\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0021 - custom_f1: 0.3050 - acc: 0.9995 - val_loss: 0.0071 - val_custom_f1: 0.2780 - val_acc: 0.9987\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0020 - custom_f1: 0.3315 - acc: 0.9995 - val_loss: 0.0083 - val_custom_f1: 0.0580 - val_acc: 0.9990\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0020 - custom_f1: 0.2935 - acc: 0.9996 - val_loss: 0.0068 - val_custom_f1: 0.1240 - val_acc: 0.9991\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0018 - custom_f1: 0.3211 - acc: 0.9996 - val_loss: 0.0056 - val_custom_f1: 0.3263 - val_acc: 0.9991\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0017 - custom_f1: 0.3498 - acc: 0.9996 - val_loss: 0.0063 - val_custom_f1: 0.3161 - val_acc: 0.9991\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0016 - custom_f1: 0.3320 - acc: 0.9996 - val_loss: 0.0057 - val_custom_f1: 0.3007 - val_acc: 0.9991\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0016 - custom_f1: 0.3400 - acc: 0.9996 - val_loss: 0.0058 - val_custom_f1: 0.2910 - val_acc: 0.9989\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0016 - custom_f1: 0.3252 - acc: 0.9996 - val_loss: 0.0063 - val_custom_f1: 0.2456 - val_acc: 0.9991\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0015 - custom_f1: 0.3606 - acc: 0.9996 - val_loss: 0.0074 - val_custom_f1: 0.1715 - val_acc: 0.9991\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0015 - custom_f1: 0.3453 - acc: 0.9996 - val_loss: 0.0063 - val_custom_f1: 0.3216 - val_acc: 0.9992\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0013 - custom_f1: 0.3560 - acc: 0.9996 - val_loss: 0.0061 - val_custom_f1: 0.3039 - val_acc: 0.9992\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0013 - custom_f1: 0.3401 - acc: 0.9996 - val_loss: 0.0058 - val_custom_f1: 0.3236 - val_acc: 0.9992\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0013 - custom_f1: 0.3524 - acc: 0.9997 - val_loss: 0.0058 - val_custom_f1: 0.3161 - val_acc: 0.9991\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0013 - custom_f1: 0.3415 - acc: 0.9996 - val_loss: 0.0057 - val_custom_f1: 0.3104 - val_acc: 0.9991\n",
            "training time: lowFramerate > port_0_17fps 89.816 s\n",
            "Training ->>> nightVideos / bridgeEntry\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 64, 64, 320)  0           conv2d_31[0][0]                  \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 320)  1280        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 64, 64, 320)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_7 (SpatialDro (None, 64, 64, 320)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.3471 - custom_f1: 0.0013 - acc: 0.9669 - val_loss: 0.2690 - val_custom_f1: 0.0000e+00 - val_acc: 0.9793\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.2000 - custom_f1: 0.0000e+00 - acc: 0.9856 - val_loss: 0.1989 - val_custom_f1: 0.0000e+00 - val_acc: 0.9793\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1763 - custom_f1: 0.0192 - acc: 0.9858 - val_loss: 0.1721 - val_custom_f1: 0.2471 - val_acc: 0.9832\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1568 - custom_f1: 0.2989 - acc: 0.9891 - val_loss: 0.1539 - val_custom_f1: 0.5725 - val_acc: 0.9879\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1400 - custom_f1: 0.5518 - acc: 0.9921 - val_loss: 0.1391 - val_custom_f1: 0.8268 - val_acc: 0.9928\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.1251 - custom_f1: 0.7590 - acc: 0.9943 - val_loss: 0.1340 - val_custom_f1: 0.7486 - val_acc: 0.9860\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1139 - custom_f1: 0.8102 - acc: 0.9951 - val_loss: 0.1159 - val_custom_f1: 0.8235 - val_acc: 0.9924\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1064 - custom_f1: 0.7857 - acc: 0.9944 - val_loss: 0.1084 - val_custom_f1: 0.8431 - val_acc: 0.9937\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0979 - custom_f1: 0.8078 - acc: 0.9953 - val_loss: 0.0976 - val_custom_f1: 0.8631 - val_acc: 0.9942\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0908 - custom_f1: 0.8290 - acc: 0.9957 - val_loss: 0.0922 - val_custom_f1: 0.8574 - val_acc: 0.9938\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0848 - custom_f1: 0.8355 - acc: 0.9957 - val_loss: 0.0871 - val_custom_f1: 0.8412 - val_acc: 0.9937\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0792 - custom_f1: 0.8352 - acc: 0.9957 - val_loss: 0.0805 - val_custom_f1: 0.8655 - val_acc: 0.9940\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0741 - custom_f1: 0.8232 - acc: 0.9959 - val_loss: 0.0781 - val_custom_f1: 0.8468 - val_acc: 0.9933\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0695 - custom_f1: 0.8308 - acc: 0.9958 - val_loss: 0.0721 - val_custom_f1: 0.8506 - val_acc: 0.9939\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0644 - custom_f1: 0.8354 - acc: 0.9961 - val_loss: 0.0674 - val_custom_f1: 0.8578 - val_acc: 0.9944\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0603 - custom_f1: 0.8458 - acc: 0.9961 - val_loss: 0.0624 - val_custom_f1: 0.8701 - val_acc: 0.9946\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0567 - custom_f1: 0.8387 - acc: 0.9962 - val_loss: 0.0584 - val_custom_f1: 0.8723 - val_acc: 0.9948\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0533 - custom_f1: 0.8518 - acc: 0.9962 - val_loss: 0.0556 - val_custom_f1: 0.8716 - val_acc: 0.9947\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0502 - custom_f1: 0.8506 - acc: 0.9965 - val_loss: 0.0528 - val_custom_f1: 0.8815 - val_acc: 0.9951\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0476 - custom_f1: 0.8598 - acc: 0.9964 - val_loss: 0.0518 - val_custom_f1: 0.8604 - val_acc: 0.9941\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0453 - custom_f1: 0.8365 - acc: 0.9964 - val_loss: 0.0509 - val_custom_f1: 0.8410 - val_acc: 0.9938\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0423 - custom_f1: 0.8573 - acc: 0.9966 - val_loss: 0.0465 - val_custom_f1: 0.8676 - val_acc: 0.9944\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0402 - custom_f1: 0.8585 - acc: 0.9965 - val_loss: 0.0461 - val_custom_f1: 0.8467 - val_acc: 0.9940\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0386 - custom_f1: 0.8627 - acc: 0.9965 - val_loss: 0.0437 - val_custom_f1: 0.8658 - val_acc: 0.9941\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0364 - custom_f1: 0.8706 - acc: 0.9969 - val_loss: 0.0425 - val_custom_f1: 0.8551 - val_acc: 0.9943\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0348 - custom_f1: 0.8660 - acc: 0.9968 - val_loss: 0.0378 - val_custom_f1: 0.8849 - val_acc: 0.9952\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0333 - custom_f1: 0.8740 - acc: 0.9968 - val_loss: 0.0384 - val_custom_f1: 0.8592 - val_acc: 0.9945\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0318 - custom_f1: 0.8558 - acc: 0.9969 - val_loss: 0.0361 - val_custom_f1: 0.8682 - val_acc: 0.9947\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0308 - custom_f1: 0.8540 - acc: 0.9967 - val_loss: 0.0357 - val_custom_f1: 0.8758 - val_acc: 0.9949\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0294 - custom_f1: 0.8630 - acc: 0.9969 - val_loss: 0.0337 - val_custom_f1: 0.8796 - val_acc: 0.9949\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0282 - custom_f1: 0.8734 - acc: 0.9968 - val_loss: 0.0338 - val_custom_f1: 0.8771 - val_acc: 0.9947\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0276 - custom_f1: 0.8664 - acc: 0.9967 - val_loss: 0.0323 - val_custom_f1: 0.8757 - val_acc: 0.9949\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0266 - custom_f1: 0.8781 - acc: 0.9970 - val_loss: 0.0318 - val_custom_f1: 0.8676 - val_acc: 0.9946\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0257 - custom_f1: 0.8644 - acc: 0.9969 - val_loss: 0.0316 - val_custom_f1: 0.8670 - val_acc: 0.9946\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0250 - custom_f1: 0.8767 - acc: 0.9969 - val_loss: 0.0295 - val_custom_f1: 0.8803 - val_acc: 0.9949\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0241 - custom_f1: 0.8676 - acc: 0.9969 - val_loss: 0.0290 - val_custom_f1: 0.8779 - val_acc: 0.9949\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0237 - custom_f1: 0.8734 - acc: 0.9969 - val_loss: 0.0278 - val_custom_f1: 0.8764 - val_acc: 0.9950\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0231 - custom_f1: 0.8657 - acc: 0.9969 - val_loss: 0.0294 - val_custom_f1: 0.8653 - val_acc: 0.9947\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0227 - custom_f1: 0.8759 - acc: 0.9969 - val_loss: 0.0274 - val_custom_f1: 0.8800 - val_acc: 0.9949\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0216 - custom_f1: 0.8794 - acc: 0.9971 - val_loss: 0.0286 - val_custom_f1: 0.8707 - val_acc: 0.9944\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0211 - custom_f1: 0.8682 - acc: 0.9970 - val_loss: 0.0287 - val_custom_f1: 0.8571 - val_acc: 0.9944\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0204 - custom_f1: 0.8717 - acc: 0.9972 - val_loss: 0.0257 - val_custom_f1: 0.8827 - val_acc: 0.9953\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0203 - custom_f1: 0.8813 - acc: 0.9970 - val_loss: 0.0251 - val_custom_f1: 0.8796 - val_acc: 0.9950\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0192 - custom_f1: 0.8874 - acc: 0.9973 - val_loss: 0.0311 - val_custom_f1: 0.8567 - val_acc: 0.9934\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0189 - custom_f1: 0.8829 - acc: 0.9972 - val_loss: 0.0253 - val_custom_f1: 0.8781 - val_acc: 0.9948\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0190 - custom_f1: 0.8813 - acc: 0.9971 - val_loss: 0.0245 - val_custom_f1: 0.8774 - val_acc: 0.9949\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0177 - custom_f1: 0.8858 - acc: 0.9973 - val_loss: 0.0255 - val_custom_f1: 0.8773 - val_acc: 0.9948\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0178 - custom_f1: 0.8811 - acc: 0.9971 - val_loss: 0.0236 - val_custom_f1: 0.8769 - val_acc: 0.9948\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0172 - custom_f1: 0.8755 - acc: 0.9972 - val_loss: 0.0234 - val_custom_f1: 0.8790 - val_acc: 0.9949\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0166 - custom_f1: 0.8668 - acc: 0.9974 - val_loss: 0.0224 - val_custom_f1: 0.8790 - val_acc: 0.9952\n",
            "training time: nightVideos > bridgeEntry 94.724 s\n",
            "Training ->>> PTZ / continuousPan\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 64, 64, 320)  0           conv2d_36[0][0]                  \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 320)  1280        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 64, 64, 320)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_8 (SpatialDro (None, 64, 64, 320)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.4226 - custom_f1: 9.2682e-06 - acc: 0.9363 - val_loss: 0.2649 - val_custom_f1: 0.0000e+00 - val_acc: 0.9677\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.2522 - custom_f1: 0.0000e+00 - acc: 0.9466 - val_loss: 0.2243 - val_custom_f1: 0.0000e+00 - val_acc: 0.9677\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.2215 - custom_f1: 0.0000e+00 - acc: 0.9466 - val_loss: 0.1943 - val_custom_f1: 0.0693 - val_acc: 0.9732\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1974 - custom_f1: 0.0626 - acc: 0.9552 - val_loss: 0.1770 - val_custom_f1: 0.2693 - val_acc: 0.9940\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1802 - custom_f1: 0.2874 - acc: 0.9823 - val_loss: 0.1650 - val_custom_f1: 0.2815 - val_acc: 0.9958\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1641 - custom_f1: 0.3398 - acc: 0.9937 - val_loss: 0.1507 - val_custom_f1: 0.2838 - val_acc: 0.9961\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1505 - custom_f1: 0.3528 - acc: 0.9946 - val_loss: 0.1378 - val_custom_f1: 0.2882 - val_acc: 0.9966\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1369 - custom_f1: 0.3576 - acc: 0.9958 - val_loss: 0.1248 - val_custom_f1: 0.2874 - val_acc: 0.9966\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1169 - custom_f1: 0.3560 - acc: 0.9948 - val_loss: 0.1098 - val_custom_f1: 0.2884 - val_acc: 0.9950\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1012 - custom_f1: 0.3590 - acc: 0.9953 - val_loss: 0.1030 - val_custom_f1: 0.2857 - val_acc: 0.9955\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0912 - custom_f1: 0.3620 - acc: 0.9968 - val_loss: 0.0945 - val_custom_f1: 0.2869 - val_acc: 0.9964\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0866 - custom_f1: 0.3618 - acc: 0.9963 - val_loss: 0.0895 - val_custom_f1: 0.2886 - val_acc: 0.9967\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0802 - custom_f1: 0.3612 - acc: 0.9970 - val_loss: 0.1186 - val_custom_f1: 0.2617 - val_acc: 0.9824\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0742 - custom_f1: 0.3648 - acc: 0.9972 - val_loss: 0.0923 - val_custom_f1: 0.2749 - val_acc: 0.9927\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0724 - custom_f1: 0.3619 - acc: 0.9962 - val_loss: 0.0894 - val_custom_f1: 0.2802 - val_acc: 0.9911\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0652 - custom_f1: 0.3649 - acc: 0.9974 - val_loss: 0.0827 - val_custom_f1: 0.2754 - val_acc: 0.9927\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0628 - custom_f1: 0.3624 - acc: 0.9968 - val_loss: 0.0827 - val_custom_f1: 0.2789 - val_acc: 0.9914\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0575 - custom_f1: 0.3654 - acc: 0.9974 - val_loss: 0.0673 - val_custom_f1: 0.2904 - val_acc: 0.9959\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0553 - custom_f1: 0.3620 - acc: 0.9970 - val_loss: 0.0600 - val_custom_f1: 0.2915 - val_acc: 0.9975\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0503 - custom_f1: 0.3659 - acc: 0.9976 - val_loss: 0.0577 - val_custom_f1: 0.2901 - val_acc: 0.9972\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0481 - custom_f1: 0.3649 - acc: 0.9971 - val_loss: 0.0754 - val_custom_f1: 0.2830 - val_acc: 0.9876\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0435 - custom_f1: 0.3658 - acc: 0.9978 - val_loss: 0.0565 - val_custom_f1: 0.2854 - val_acc: 0.9952\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0437 - custom_f1: 0.3619 - acc: 0.9971 - val_loss: 0.0525 - val_custom_f1: 0.2883 - val_acc: 0.9965\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0394 - custom_f1: 0.3669 - acc: 0.9978 - val_loss: 0.0486 - val_custom_f1: 0.2908 - val_acc: 0.9971\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0386 - custom_f1: 0.3655 - acc: 0.9975 - val_loss: 0.0467 - val_custom_f1: 0.2905 - val_acc: 0.9972\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0364 - custom_f1: 0.3649 - acc: 0.9976 - val_loss: 0.0445 - val_custom_f1: 0.2908 - val_acc: 0.9972\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0339 - custom_f1: 0.3664 - acc: 0.9979 - val_loss: 0.0419 - val_custom_f1: 0.2912 - val_acc: 0.9974\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0320 - custom_f1: 0.3647 - acc: 0.9979 - val_loss: 0.0416 - val_custom_f1: 0.2891 - val_acc: 0.9969\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0312 - custom_f1: 0.3659 - acc: 0.9977 - val_loss: 0.0389 - val_custom_f1: 0.2900 - val_acc: 0.9972\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0294 - custom_f1: 0.3662 - acc: 0.9978 - val_loss: 0.0407 - val_custom_f1: 0.2915 - val_acc: 0.9959\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0272 - custom_f1: 0.3669 - acc: 0.9981 - val_loss: 0.0374 - val_custom_f1: 0.2915 - val_acc: 0.9959\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0260 - custom_f1: 0.3653 - acc: 0.9980 - val_loss: 0.0389 - val_custom_f1: 0.2855 - val_acc: 0.9958\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0266 - custom_f1: 0.3644 - acc: 0.9974 - val_loss: 0.0338 - val_custom_f1: 0.2916 - val_acc: 0.9974\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0242 - custom_f1: 0.3664 - acc: 0.9981 - val_loss: 0.0335 - val_custom_f1: 0.2906 - val_acc: 0.9971\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0233 - custom_f1: 0.3673 - acc: 0.9982 - val_loss: 0.0355 - val_custom_f1: 0.3168 - val_acc: 0.9957\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0226 - custom_f1: 0.3665 - acc: 0.9980 - val_loss: 0.0341 - val_custom_f1: 0.2863 - val_acc: 0.9963\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0216 - custom_f1: 0.3671 - acc: 0.9981 - val_loss: 0.0317 - val_custom_f1: 0.2887 - val_acc: 0.9968\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0203 - custom_f1: 0.3670 - acc: 0.9982 - val_loss: 0.0278 - val_custom_f1: 0.2910 - val_acc: 0.9975\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0198 - custom_f1: 0.3675 - acc: 0.9982 - val_loss: 0.0276 - val_custom_f1: 0.2997 - val_acc: 0.9975\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0193 - custom_f1: 0.3674 - acc: 0.9981 - val_loss: 0.0289 - val_custom_f1: 0.2912 - val_acc: 0.9974\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0179 - custom_f1: 0.3671 - acc: 0.9983 - val_loss: 0.0270 - val_custom_f1: 0.2915 - val_acc: 0.9975\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0170 - custom_f1: 0.3678 - acc: 0.9983 - val_loss: 0.0326 - val_custom_f1: 0.2840 - val_acc: 0.9953\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0164 - custom_f1: 0.3674 - acc: 0.9983 - val_loss: 0.0272 - val_custom_f1: 0.2902 - val_acc: 0.9970\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0153 - custom_f1: 0.3677 - acc: 0.9984 - val_loss: 0.0246 - val_custom_f1: 0.2920 - val_acc: 0.9976\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0152 - custom_f1: 0.3681 - acc: 0.9983 - val_loss: 0.0245 - val_custom_f1: 0.2918 - val_acc: 0.9971\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0169 - custom_f1: 0.3667 - acc: 0.9978 - val_loss: 0.0241 - val_custom_f1: 0.2903 - val_acc: 0.9973\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0160 - custom_f1: 0.3675 - acc: 0.9977 - val_loss: 0.0250 - val_custom_f1: 0.2906 - val_acc: 0.9970\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0137 - custom_f1: 0.3682 - acc: 0.9984 - val_loss: 0.0235 - val_custom_f1: 0.2922 - val_acc: 0.9973\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0134 - custom_f1: 0.3682 - acc: 0.9984 - val_loss: 0.0250 - val_custom_f1: 0.2902 - val_acc: 0.9969\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0135 - custom_f1: 0.3680 - acc: 0.9982 - val_loss: 0.0326 - val_custom_f1: 0.3059 - val_acc: 0.9947\n",
            "training time: PTZ > continuousPan 94.811 s\n",
            "Training ->>> shadow / backdoor\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 64, 64, 320)  0           conv2d_41[0][0]                  \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 64, 64, 320)  1280        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 64, 64, 320)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_9 (SpatialDro (None, 64, 64, 320)  0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.4084 - custom_f1: 0.0042 - acc: 0.9256 - val_loss: 0.2498 - val_custom_f1: 0.0000e+00 - val_acc: 0.9451\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.2322 - custom_f1: 0.0905 - acc: 0.9478 - val_loss: 0.2217 - val_custom_f1: 0.6122 - val_acc: 0.9703\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.2063 - custom_f1: 0.6830 - acc: 0.9745 - val_loss: 0.1945 - val_custom_f1: 0.8651 - val_acc: 0.9857\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1840 - custom_f1: 0.9001 - acc: 0.9893 - val_loss: 0.1733 - val_custom_f1: 0.9015 - val_acc: 0.9895\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1537 - custom_f1: 0.9253 - acc: 0.9916 - val_loss: 0.1439 - val_custom_f1: 0.9259 - val_acc: 0.9912\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1364 - custom_f1: 0.9346 - acc: 0.9926 - val_loss: 0.1326 - val_custom_f1: 0.9294 - val_acc: 0.9916\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1258 - custom_f1: 0.9384 - acc: 0.9932 - val_loss: 0.1244 - val_custom_f1: 0.9294 - val_acc: 0.9914\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1164 - custom_f1: 0.9415 - acc: 0.9935 - val_loss: 0.1152 - val_custom_f1: 0.9325 - val_acc: 0.9919\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1069 - custom_f1: 0.9469 - acc: 0.9940 - val_loss: 0.1076 - val_custom_f1: 0.9342 - val_acc: 0.9921\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1000 - custom_f1: 0.9467 - acc: 0.9940 - val_loss: 0.1020 - val_custom_f1: 0.9323 - val_acc: 0.9916\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0935 - custom_f1: 0.9474 - acc: 0.9941 - val_loss: 0.0940 - val_custom_f1: 0.9348 - val_acc: 0.9922\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0867 - custom_f1: 0.9499 - acc: 0.9944 - val_loss: 0.0886 - val_custom_f1: 0.9335 - val_acc: 0.9920\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0808 - custom_f1: 0.9503 - acc: 0.9944 - val_loss: 0.0819 - val_custom_f1: 0.9352 - val_acc: 0.9927\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0754 - custom_f1: 0.9508 - acc: 0.9946 - val_loss: 0.0804 - val_custom_f1: 0.9308 - val_acc: 0.9920\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0706 - custom_f1: 0.9521 - acc: 0.9948 - val_loss: 0.0731 - val_custom_f1: 0.9379 - val_acc: 0.9931\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0665 - custom_f1: 0.9530 - acc: 0.9948 - val_loss: 0.0704 - val_custom_f1: 0.9308 - val_acc: 0.9928\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0624 - custom_f1: 0.9549 - acc: 0.9949 - val_loss: 0.0654 - val_custom_f1: 0.9406 - val_acc: 0.9929\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0582 - custom_f1: 0.9564 - acc: 0.9952 - val_loss: 0.0633 - val_custom_f1: 0.9327 - val_acc: 0.9928\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0547 - custom_f1: 0.9577 - acc: 0.9952 - val_loss: 0.0589 - val_custom_f1: 0.9418 - val_acc: 0.9931\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0517 - custom_f1: 0.9576 - acc: 0.9952 - val_loss: 0.0551 - val_custom_f1: 0.9446 - val_acc: 0.9935\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0488 - custom_f1: 0.9572 - acc: 0.9953 - val_loss: 0.0514 - val_custom_f1: 0.9440 - val_acc: 0.9938\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0460 - custom_f1: 0.9590 - acc: 0.9954 - val_loss: 0.0495 - val_custom_f1: 0.9437 - val_acc: 0.9936\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0436 - custom_f1: 0.9589 - acc: 0.9955 - val_loss: 0.0484 - val_custom_f1: 0.9405 - val_acc: 0.9934\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0415 - custom_f1: 0.9581 - acc: 0.9955 - val_loss: 0.0474 - val_custom_f1: 0.9360 - val_acc: 0.9930\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0401 - custom_f1: 0.9588 - acc: 0.9954 - val_loss: 0.0446 - val_custom_f1: 0.9420 - val_acc: 0.9934\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0378 - custom_f1: 0.9610 - acc: 0.9957 - val_loss: 0.0438 - val_custom_f1: 0.9396 - val_acc: 0.9934\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0366 - custom_f1: 0.9600 - acc: 0.9955 - val_loss: 0.0434 - val_custom_f1: 0.9389 - val_acc: 0.9932\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0349 - custom_f1: 0.9613 - acc: 0.9957 - val_loss: 0.0415 - val_custom_f1: 0.9412 - val_acc: 0.9931\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0336 - custom_f1: 0.9610 - acc: 0.9957 - val_loss: 0.0421 - val_custom_f1: 0.9373 - val_acc: 0.9929\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0330 - custom_f1: 0.9610 - acc: 0.9956 - val_loss: 0.0397 - val_custom_f1: 0.9405 - val_acc: 0.9936\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0308 - custom_f1: 0.9644 - acc: 0.9960 - val_loss: 0.0357 - val_custom_f1: 0.9484 - val_acc: 0.9941\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0301 - custom_f1: 0.9626 - acc: 0.9959 - val_loss: 0.0356 - val_custom_f1: 0.9420 - val_acc: 0.9935\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0287 - custom_f1: 0.9642 - acc: 0.9960 - val_loss: 0.0364 - val_custom_f1: 0.9409 - val_acc: 0.9934\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0285 - custom_f1: 0.9626 - acc: 0.9958 - val_loss: 0.0353 - val_custom_f1: 0.9402 - val_acc: 0.9936\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0269 - custom_f1: 0.9646 - acc: 0.9961 - val_loss: 0.0382 - val_custom_f1: 0.9293 - val_acc: 0.9930\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0262 - custom_f1: 0.9651 - acc: 0.9961 - val_loss: 0.0331 - val_custom_f1: 0.9426 - val_acc: 0.9938\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0252 - custom_f1: 0.9658 - acc: 0.9963 - val_loss: 0.0343 - val_custom_f1: 0.9408 - val_acc: 0.9935\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0253 - custom_f1: 0.9631 - acc: 0.9959 - val_loss: 0.0333 - val_custom_f1: 0.9408 - val_acc: 0.9937\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0241 - custom_f1: 0.9655 - acc: 0.9962 - val_loss: 0.0317 - val_custom_f1: 0.9437 - val_acc: 0.9937\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0235 - custom_f1: 0.9645 - acc: 0.9961 - val_loss: 0.0361 - val_custom_f1: 0.9371 - val_acc: 0.9928\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0231 - custom_f1: 0.9638 - acc: 0.9961 - val_loss: 0.0289 - val_custom_f1: 0.9449 - val_acc: 0.9938\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0224 - custom_f1: 0.9660 - acc: 0.9962 - val_loss: 0.0318 - val_custom_f1: 0.9384 - val_acc: 0.9934\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0217 - custom_f1: 0.9664 - acc: 0.9963 - val_loss: 0.0304 - val_custom_f1: 0.9389 - val_acc: 0.9934\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0213 - custom_f1: 0.9671 - acc: 0.9964 - val_loss: 0.0310 - val_custom_f1: 0.9440 - val_acc: 0.9935\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0209 - custom_f1: 0.9658 - acc: 0.9963 - val_loss: 0.0288 - val_custom_f1: 0.9455 - val_acc: 0.9936\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0206 - custom_f1: 0.9665 - acc: 0.9963 - val_loss: 0.0299 - val_custom_f1: 0.9444 - val_acc: 0.9938\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0201 - custom_f1: 0.9658 - acc: 0.9962 - val_loss: 0.0291 - val_custom_f1: 0.9432 - val_acc: 0.9936\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0197 - custom_f1: 0.9676 - acc: 0.9963 - val_loss: 0.0285 - val_custom_f1: 0.9422 - val_acc: 0.9937\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0192 - custom_f1: 0.9672 - acc: 0.9964 - val_loss: 0.0286 - val_custom_f1: 0.9411 - val_acc: 0.9936\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0187 - custom_f1: 0.9668 - acc: 0.9964 - val_loss: 0.0300 - val_custom_f1: 0.9382 - val_acc: 0.9934\n",
            "training time: shadow > backdoor 94.497 s\n",
            "Training ->>> thermal / corridor\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 64, 64, 320)  0           conv2d_46[0][0]                  \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 64, 320)  1280        concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 64, 64, 320)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_10 (SpatialDr (None, 64, 64, 320)  0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.4642 - custom_f1: 0.0089 - acc: 0.8876 - val_loss: 0.2479 - val_custom_f1: 0.0000e+00 - val_acc: 0.9646\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.2936 - custom_f1: 0.0000e+00 - acc: 0.8962 - val_loss: 0.2388 - val_custom_f1: 0.0075 - val_acc: 0.9646\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.2547 - custom_f1: 0.5678 - acc: 0.9452 - val_loss: 0.1975 - val_custom_f1: 0.4400 - val_acc: 0.9836\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.2361 - custom_f1: 0.8349 - acc: 0.9767 - val_loss: 0.1889 - val_custom_f1: 0.7242 - val_acc: 0.9842\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1844 - custom_f1: 0.8978 - acc: 0.9892 - val_loss: 0.1599 - val_custom_f1: 0.8187 - val_acc: 0.9905\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.1618 - custom_f1: 0.9097 - acc: 0.9906 - val_loss: 0.1488 - val_custom_f1: 0.8417 - val_acc: 0.9920\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1500 - custom_f1: 0.9104 - acc: 0.9916 - val_loss: 0.1396 - val_custom_f1: 0.8537 - val_acc: 0.9932\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1404 - custom_f1: 0.9154 - acc: 0.9920 - val_loss: 0.1379 - val_custom_f1: 0.8272 - val_acc: 0.9915\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1316 - custom_f1: 0.9126 - acc: 0.9929 - val_loss: 0.1294 - val_custom_f1: 0.8030 - val_acc: 0.9923\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1232 - custom_f1: 0.9238 - acc: 0.9936 - val_loss: 0.1197 - val_custom_f1: 0.8375 - val_acc: 0.9934\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1168 - custom_f1: 0.9258 - acc: 0.9936 - val_loss: 0.1154 - val_custom_f1: 0.8487 - val_acc: 0.9930\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1099 - custom_f1: 0.9263 - acc: 0.9938 - val_loss: 0.1093 - val_custom_f1: 0.8248 - val_acc: 0.9934\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1040 - custom_f1: 0.9375 - acc: 0.9941 - val_loss: 0.1041 - val_custom_f1: 0.8565 - val_acc: 0.9934\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0997 - custom_f1: 0.9338 - acc: 0.9939 - val_loss: 0.0973 - val_custom_f1: 0.8595 - val_acc: 0.9940\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0928 - custom_f1: 0.9330 - acc: 0.9945 - val_loss: 0.0920 - val_custom_f1: 0.8635 - val_acc: 0.9943\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0899 - custom_f1: 0.9385 - acc: 0.9941 - val_loss: 0.0904 - val_custom_f1: 0.8750 - val_acc: 0.9935\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0829 - custom_f1: 0.9506 - acc: 0.9950 - val_loss: 0.0835 - val_custom_f1: 0.8598 - val_acc: 0.9942\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0785 - custom_f1: 0.9303 - acc: 0.9950 - val_loss: 0.0794 - val_custom_f1: 0.8324 - val_acc: 0.9940\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0769 - custom_f1: 0.9424 - acc: 0.9943 - val_loss: 0.0762 - val_custom_f1: 0.8625 - val_acc: 0.9943\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0718 - custom_f1: 0.9507 - acc: 0.9952 - val_loss: 0.0748 - val_custom_f1: 0.8271 - val_acc: 0.9937\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0687 - custom_f1: 0.9421 - acc: 0.9951 - val_loss: 0.0854 - val_custom_f1: 0.7111 - val_acc: 0.9901\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0648 - custom_f1: 0.9516 - acc: 0.9953 - val_loss: 0.0675 - val_custom_f1: 0.8555 - val_acc: 0.9942\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0611 - custom_f1: 0.9490 - acc: 0.9956 - val_loss: 0.0651 - val_custom_f1: 0.8722 - val_acc: 0.9941\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0593 - custom_f1: 0.9501 - acc: 0.9953 - val_loss: 0.0642 - val_custom_f1: 0.8453 - val_acc: 0.9940\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0568 - custom_f1: 0.9550 - acc: 0.9954 - val_loss: 0.0630 - val_custom_f1: 0.8808 - val_acc: 0.9938\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0542 - custom_f1: 0.9525 - acc: 0.9955 - val_loss: 0.0603 - val_custom_f1: 0.8528 - val_acc: 0.9937\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0519 - custom_f1: 0.9561 - acc: 0.9957 - val_loss: 0.0582 - val_custom_f1: 0.8740 - val_acc: 0.9937\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0504 - custom_f1: 0.9562 - acc: 0.9955 - val_loss: 0.0543 - val_custom_f1: 0.8583 - val_acc: 0.9942\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0473 - custom_f1: 0.9559 - acc: 0.9959 - val_loss: 0.0503 - val_custom_f1: 0.8723 - val_acc: 0.9945\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0461 - custom_f1: 0.9555 - acc: 0.9957 - val_loss: 0.0498 - val_custom_f1: 0.8427 - val_acc: 0.9944\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0443 - custom_f1: 0.9560 - acc: 0.9958 - val_loss: 0.0488 - val_custom_f1: 0.8780 - val_acc: 0.9946\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0424 - custom_f1: 0.9552 - acc: 0.9958 - val_loss: 0.0473 - val_custom_f1: 0.8895 - val_acc: 0.9946\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0406 - custom_f1: 0.9600 - acc: 0.9961 - val_loss: 0.0513 - val_custom_f1: 0.8852 - val_acc: 0.9940\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0393 - custom_f1: 0.9569 - acc: 0.9958 - val_loss: 0.0462 - val_custom_f1: 0.8594 - val_acc: 0.9935\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0386 - custom_f1: 0.9586 - acc: 0.9958 - val_loss: 0.0428 - val_custom_f1: 0.8674 - val_acc: 0.9947\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0372 - custom_f1: 0.9473 - acc: 0.9959 - val_loss: 0.0434 - val_custom_f1: 0.8648 - val_acc: 0.9943\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0356 - custom_f1: 0.9594 - acc: 0.9961 - val_loss: 0.0424 - val_custom_f1: 0.8824 - val_acc: 0.9943\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0343 - custom_f1: 0.9614 - acc: 0.9962 - val_loss: 0.0413 - val_custom_f1: 0.8583 - val_acc: 0.9941\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0331 - custom_f1: 0.9633 - acc: 0.9963 - val_loss: 0.0413 - val_custom_f1: 0.8671 - val_acc: 0.9940\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0332 - custom_f1: 0.9505 - acc: 0.9960 - val_loss: 0.0409 - val_custom_f1: 0.8469 - val_acc: 0.9941\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0322 - custom_f1: 0.9412 - acc: 0.9960 - val_loss: 0.0351 - val_custom_f1: 0.8808 - val_acc: 0.9949\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0304 - custom_f1: 0.9600 - acc: 0.9963 - val_loss: 0.0384 - val_custom_f1: 0.8842 - val_acc: 0.9942\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0299 - custom_f1: 0.9593 - acc: 0.9962 - val_loss: 0.0405 - val_custom_f1: 0.8267 - val_acc: 0.9935\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0292 - custom_f1: 0.9587 - acc: 0.9963 - val_loss: 0.0335 - val_custom_f1: 0.8868 - val_acc: 0.9947\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0281 - custom_f1: 0.9600 - acc: 0.9962 - val_loss: 0.0355 - val_custom_f1: 0.8547 - val_acc: 0.9944\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0274 - custom_f1: 0.9544 - acc: 0.9963 - val_loss: 0.0337 - val_custom_f1: 0.8823 - val_acc: 0.9945\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0263 - custom_f1: 0.9625 - acc: 0.9965 - val_loss: 0.0320 - val_custom_f1: 0.8797 - val_acc: 0.9948\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0262 - custom_f1: 0.9612 - acc: 0.9963 - val_loss: 0.0376 - val_custom_f1: 0.8132 - val_acc: 0.9936\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0254 - custom_f1: 0.9579 - acc: 0.9964 - val_loss: 0.0343 - val_custom_f1: 0.8818 - val_acc: 0.9942\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0251 - custom_f1: 0.9466 - acc: 0.9964 - val_loss: 0.0348 - val_custom_f1: 0.8758 - val_acc: 0.9939\n",
            "training time: thermal > corridor 94.359 s\n",
            "Training ->>> turbulence / turbulence0\n",
            "Model: \"vision_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 64, 64, 512)  1180160     block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dr1 (Dropout)                   (None, 64, 64, 512)  0           block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 64, 64, 512)  2359808     dr1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr2 (Dropout)                   (None, 64, 64, 512)  0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 64, 64, 512)  2359808     dr2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dr3 (Dropout)                   (None, 64, 64, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 64, 64, 512)  0           dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 64, 64, 64)   32832       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 64, 64, 64)   294976      dr3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 64, 64, 320)  0           conv2d_51[0][0]                  \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 320)  1280        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 64, 64, 320)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_11 (SpatialDr (None, 64, 64, 320)  0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   20544       spatial_dropout2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv2 (Conv2DTranspose) (None, 64, 64, 64)   36928       block5_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block5_tconv3 (Conv2DTranspose) (None, 64, 64, 512)  33280       block5_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv1 (Conv2DTranspose) (None, 64, 64, 64)   32832       block5_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 102464      block6_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block6_tconv3 (Conv2DTranspose) (None, 128, 128, 256 16640       block6_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv1 (Conv2DTranspose) (None, 128, 128, 64) 16448       block6_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv2 (Conv2DTranspose) (None, 128, 128, 64) 36928       block7_tconv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block7_tconv3 (Conv2DTranspose) (None, 128, 128, 128 8320        block7_tconv2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2DTranspose)  (None, 256, 256, 64) 204864      block7_tconv3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2DTranspose)  (None, 256, 256, 1)  65          block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 256, 256, 1)  0           block9_conv1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 9,358,593\n",
            "Trainable params: 7,622,465\n",
            "Non-trainable params: 1,736,128\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40 samples, validate on 10 samples\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 3s 74ms/step - loss: 0.3187 - custom_f1: 0.0000e+00 - acc: 0.9970 - val_loss: 0.1914 - val_custom_f1: 0.0000e+00 - val_acc: 0.9974\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.1814 - custom_f1: 0.0000e+00 - acc: 0.9970 - val_loss: 0.1687 - val_custom_f1: 0.0000e+00 - val_acc: 0.9974\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1584 - custom_f1: 0.0000e+00 - acc: 0.9970 - val_loss: 0.1468 - val_custom_f1: 0.0806 - val_acc: 0.9975\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1372 - custom_f1: 0.2485 - acc: 0.9975 - val_loss: 0.1269 - val_custom_f1: 0.4063 - val_acc: 0.9981\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.1190 - custom_f1: 0.5619 - acc: 0.9982 - val_loss: 0.1104 - val_custom_f1: 0.4670 - val_acc: 0.9982\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.1034 - custom_f1: 0.6722 - acc: 0.9986 - val_loss: 0.0964 - val_custom_f1: 0.7776 - val_acc: 0.9989\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0903 - custom_f1: 0.7395 - acc: 0.9988 - val_loss: 0.0840 - val_custom_f1: 0.6560 - val_acc: 0.9988\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0790 - custom_f1: 0.7828 - acc: 0.9990 - val_loss: 0.0735 - val_custom_f1: 0.8531 - val_acc: 0.9992\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0692 - custom_f1: 0.8146 - acc: 0.9991 - val_loss: 0.0648 - val_custom_f1: 0.8481 - val_acc: 0.9992\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0604 - custom_f1: 0.8492 - acc: 0.9992 - val_loss: 0.0565 - val_custom_f1: 0.8362 - val_acc: 0.9992\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0535 - custom_f1: 0.8387 - acc: 0.9992 - val_loss: 0.0502 - val_custom_f1: 0.8456 - val_acc: 0.9992\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0473 - custom_f1: 0.8520 - acc: 0.9992 - val_loss: 0.0443 - val_custom_f1: 0.8672 - val_acc: 0.9993\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0418 - custom_f1: 0.8556 - acc: 0.9993 - val_loss: 0.0392 - val_custom_f1: 0.8447 - val_acc: 0.9992\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0366 - custom_f1: 0.8667 - acc: 0.9994 - val_loss: 0.0346 - val_custom_f1: 0.8472 - val_acc: 0.9992\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.0323 - custom_f1: 0.8677 - acc: 0.9993 - val_loss: 0.0305 - val_custom_f1: 0.8505 - val_acc: 0.9993\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0284 - custom_f1: 0.8615 - acc: 0.9993 - val_loss: 0.0268 - val_custom_f1: 0.8763 - val_acc: 0.9993\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0249 - custom_f1: 0.8689 - acc: 0.9993 - val_loss: 0.0235 - val_custom_f1: 0.8597 - val_acc: 0.9993\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0221 - custom_f1: 0.8591 - acc: 0.9993 - val_loss: 0.0214 - val_custom_f1: 0.8290 - val_acc: 0.9992\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0195 - custom_f1: 0.8653 - acc: 0.9993 - val_loss: 0.0181 - val_custom_f1: 0.8543 - val_acc: 0.9993\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0171 - custom_f1: 0.8643 - acc: 0.9993 - val_loss: 0.0169 - val_custom_f1: 0.7703 - val_acc: 0.9992\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0150 - custom_f1: 0.8672 - acc: 0.9994 - val_loss: 0.0144 - val_custom_f1: 0.8255 - val_acc: 0.9993\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0133 - custom_f1: 0.8792 - acc: 0.9993 - val_loss: 0.0129 - val_custom_f1: 0.8406 - val_acc: 0.9993\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0119 - custom_f1: 0.8661 - acc: 0.9993 - val_loss: 0.0116 - val_custom_f1: 0.8626 - val_acc: 0.9993\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0106 - custom_f1: 0.8655 - acc: 0.9993 - val_loss: 0.0112 - val_custom_f1: 0.7595 - val_acc: 0.9991\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0095 - custom_f1: 0.8659 - acc: 0.9993 - val_loss: 0.0091 - val_custom_f1: 0.8634 - val_acc: 0.9993\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0085 - custom_f1: 0.8693 - acc: 0.9994 - val_loss: 0.0082 - val_custom_f1: 0.8550 - val_acc: 0.9993\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0076 - custom_f1: 0.8913 - acc: 0.9994 - val_loss: 0.0074 - val_custom_f1: 0.8632 - val_acc: 0.9993\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0071 - custom_f1: 0.8702 - acc: 0.9994 - val_loss: 0.0069 - val_custom_f1: 0.8523 - val_acc: 0.9993\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0063 - custom_f1: 0.8821 - acc: 0.9994 - val_loss: 0.0066 - val_custom_f1: 0.8473 - val_acc: 0.9993\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0060 - custom_f1: 0.8741 - acc: 0.9994 - val_loss: 0.0062 - val_custom_f1: 0.8482 - val_acc: 0.9993\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0055 - custom_f1: 0.8900 - acc: 0.9994 - val_loss: 0.0054 - val_custom_f1: 0.8892 - val_acc: 0.9994\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0051 - custom_f1: 0.8762 - acc: 0.9994 - val_loss: 0.0054 - val_custom_f1: 0.8404 - val_acc: 0.9992\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0048 - custom_f1: 0.8890 - acc: 0.9994 - val_loss: 0.0051 - val_custom_f1: 0.8343 - val_acc: 0.9993\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0046 - custom_f1: 0.8754 - acc: 0.9994 - val_loss: 0.0045 - val_custom_f1: 0.8738 - val_acc: 0.9994\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0043 - custom_f1: 0.8742 - acc: 0.9994 - val_loss: 0.0043 - val_custom_f1: 0.8721 - val_acc: 0.9994\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0041 - custom_f1: 0.8969 - acc: 0.9994 - val_loss: 0.0043 - val_custom_f1: 0.8616 - val_acc: 0.9993\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0039 - custom_f1: 0.8800 - acc: 0.9994 - val_loss: 0.0040 - val_custom_f1: 0.8663 - val_acc: 0.9994\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0037 - custom_f1: 0.9003 - acc: 0.9994 - val_loss: 0.0044 - val_custom_f1: 0.8520 - val_acc: 0.9992\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0036 - custom_f1: 0.8618 - acc: 0.9994 - val_loss: 0.0038 - val_custom_f1: 0.8663 - val_acc: 0.9994\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0034 - custom_f1: 0.8835 - acc: 0.9994 - val_loss: 0.0035 - val_custom_f1: 0.8721 - val_acc: 0.9993\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0034 - custom_f1: 0.8866 - acc: 0.9994 - val_loss: 0.0034 - val_custom_f1: 0.8727 - val_acc: 0.9994\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0032 - custom_f1: 0.8840 - acc: 0.9994 - val_loss: 0.0033 - val_custom_f1: 0.8759 - val_acc: 0.9994\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0031 - custom_f1: 0.8903 - acc: 0.9994 - val_loss: 0.0033 - val_custom_f1: 0.8832 - val_acc: 0.9994\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0029 - custom_f1: 0.8839 - acc: 0.9994 - val_loss: 0.0032 - val_custom_f1: 0.8773 - val_acc: 0.9994\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.0028 - custom_f1: 0.9077 - acc: 0.9995 - val_loss: 0.0030 - val_custom_f1: 0.8829 - val_acc: 0.9994\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0028 - custom_f1: 0.8820 - acc: 0.9994 - val_loss: 0.0034 - val_custom_f1: 0.8664 - val_acc: 0.9993\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0027 - custom_f1: 0.9060 - acc: 0.9995 - val_loss: 0.0029 - val_custom_f1: 0.8697 - val_acc: 0.9994\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0027 - custom_f1: 0.8990 - acc: 0.9994 - val_loss: 0.0030 - val_custom_f1: 0.8810 - val_acc: 0.9994\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.0025 - custom_f1: 0.8846 - acc: 0.9995 - val_loss: 0.0028 - val_custom_f1: 0.8869 - val_acc: 0.9994\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.0025 - custom_f1: 0.9041 - acc: 0.9995 - val_loss: 0.0029 - val_custom_f1: 0.8758 - val_acc: 0.9994\n",
            "training time: turbulence > turbulence0 95.7 s\n"
          ]
        }
      ]
    }
  ]
}